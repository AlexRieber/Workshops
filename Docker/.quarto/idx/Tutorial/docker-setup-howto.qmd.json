{"title":"Docker Setup Guide for AI Coding Agents","markdown":{"yaml":{"title":"Docker Setup Guide for AI Coding Agents","author":"Alexander Rieber ([\\@AlexRieber](https://github.com/AlexRieber)) · Ulm University","date":"2026-02-25","format":{"html":{"theme":"cosmo","css":"howto-html.css","toc":true,"toc-depth":3,"number-sections":true,"embed-resources":true,"highlight-style":"github-dark","code-overflow":"wrap","link-external-newwindow":true}},"filters":["os-boxes.lua"]},"headingText":"Part 1: What is Docker and Why Do We Need It?","containsRefs":false,"markdown":"\n\n::: {.callout-note appearance=\"simple\"}\n**Who is this for?** Students who have never used Docker before and want to set up a safe, reproducible environment for running AI coding agents (Claude Code, OpenAI Codex, Google Gemini CLI, and Aider) alongside R, Python, and Stata.\n\n**What you need:** A Windows, Mac, or Linux computer with at least 16 GB RAM and 80 GB free disk space.\n\n**Workshop materials:** All files (Dockerfile, docker-compose.yml, CLAUDE.md, this guide) are available at **[github.com/AlexRieber/Workshops/Docker](https://github.com/AlexRieber/Workshops/tree/main/Docker)**.\n:::\n\n---\n\n\n## The Problem\n\nImagine you want to let an AI agent write and run code on your computer. That agent can:\n\n- Install software packages\n- Download files from the internet\n- Create, modify, and delete files\n- Run arbitrary shell commands\n\nLetting an AI do all that directly on your laptop is risky. It might accidentally delete important files, install conflicting software, or fill up your hard drive. And if something goes wrong, cleaning up the mess can be painful.\n\n## The Solution: A Sandbox\n\n**Docker** lets you create an isolated \"mini-computer\" (called a **container**) that runs inside your real computer. Think of it as a virtual room where the AI agent can work freely. If anything goes wrong, you simply delete the container and start fresh --- your actual system remains untouched.\n\n## Three Concepts You Need to Know\n\n| Concept | Analogy | What It Is |\n|---------|---------|------------|\n| **Dockerfile** | A recipe | A text file with instructions: \"Install R, install Python, install Claude Code, set up these folders...\" |\n| **Image** | A frozen meal | The result of following the recipe --- a snapshot of a complete environment, ready to use |\n| **Container** | The meal, heated up and on your plate | A running instance of the image where you actually work |\n\n## Why Docker for This Workshop?\n\n| Benefit | What It Means for You |\n|---------|-----------------------|\n| **Safety (sandbox)** | The AI agent cannot touch your files, your system, or your other software. Everything stays inside the container. |\n| **Reproducibility** | Every student gets the exact same environment. No more \"it works on my machine\" problems. |\n| **Easy cleanup** | Done with the project? Delete the container and image. Your system is clean again. |\n| **Portability** | Share the Dockerfile with a colleague and they can rebuild the exact same setup in minutes. |\n\n---\n\n# Part 2: Installing Docker\n\n## Option A: Docker Desktop (Recommended for Beginners)\n\nDocker Desktop is a free application that lets you run containers on Windows and Mac (and Linux, though most Linux users prefer Docker Engine directly). It provides a graphical interface and handles all the technical complexity behind the scenes.\n\n::: {.callout-tip}\n## Good news for students and educators\nDocker Desktop is **free for educational use**. Docker's subscription terms explicitly exempt educational institutions, so you can use Docker Desktop at university without any licensing concerns.\n:::\n\n::: {.windows}\n\n## Windows (with Docker Desktop)\n\n**Prerequisites:** Windows 10 version 2004 or higher, or Windows 11. You need administrator access.\n\n**Step 1: Enable WSL 2** (Windows Subsystem for Linux)\n\nWSL 2 lets Docker run a lightweight Linux kernel inside Windows. This is required.\n\n1. Open **PowerShell as Administrator** (right-click the Start button, select \"Terminal (Admin)\" or \"Windows PowerShell (Admin)\")\n2. Run:\n\n```powershell\nwsl --install\n```\n\n3. **Restart your computer** when prompted\n4. After restart, a window will open asking you to create a Linux username and password. Choose something simple you will remember (e.g., your first name as username). **This is NOT your Windows password** --- it is a new, separate password for the Linux subsystem.\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 5--10 minutes (including restart)\n:::\n\n**Step 2: Install Docker Desktop**\n\n1. Go to: **[https://www.docker.com/products/docker-desktop/](https://www.docker.com/products/docker-desktop/)**\n2. Click **\"Download for Windows\"**\n3. Run the downloaded installer (`Docker Desktop Installer.exe`)\n4. Keep all default settings and click through the installer\n5. When installation finishes, **restart your computer** if prompted\n6. Docker Desktop should start automatically after login. You will see a whale icon in your system tray (bottom-right).\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 5--10 minutes (including download)\n:::\n\n**Step 3: Configure Docker Desktop**\n\n1. Open Docker Desktop (click the whale icon in the system tray)\n2. If you see a \"Service Agreement\" screen, click **Accept**\n3. You can skip or close the tutorial/sign-in prompts --- you do NOT need a Docker account\n4. Go to **Settings** (gear icon, top-right):\n   - **General** tab: Make sure **\"Use the WSL 2 based engine\"** is checked (it usually is by default)\n   - **Resources → WSL Integration** tab: Toggle ON the switch next to your Ubuntu distribution\n   - Click **\"Apply & restart\"**\n\n**Step 4: Verify the Installation**\n\nOpen **Ubuntu** from your Start menu (NOT PowerShell, NOT CMD --- use the Ubuntu app that WSL installed):\n\n```bash\ndocker --version\n```\n\nYou should see something like `Docker version 27.x.x`. Now test that Docker can run containers:\n\n```bash\ndocker run hello-world\n```\n\nYou should see a message starting with `Hello from Docker!`. If so, Docker is working.\n\n::: {.callout-important}\nFrom now on, **always work in the Ubuntu/WSL terminal** for all Docker commands. Do not use PowerShell or CMD.\n:::\n\n:::\n\n::: {.mac}\n\n## Mac\n\n**Prerequisites:** macOS 14 (Sonoma) or later. You need administrator access. Check whether your Mac has an **Apple Silicon** chip (M1, M2, M3, M4) or an **Intel** chip: click the Apple menu, select \"About This Mac\", and look at the \"Chip\" line.\n\n**Step 1: Install Docker Desktop**\n\n1. Go to: **[https://www.docker.com/products/docker-desktop/](https://www.docker.com/products/docker-desktop/)**\n2. Click **\"Download for Mac\"**\n   - If you have Apple Silicon (M1/M2/M3/M4): select **\"Apple Silicon\"** (this is the default now)\n   - If you have Intel: select **\"Intel chip\"**\n3. Open the downloaded `.dmg` file\n4. Drag the Docker icon into your Applications folder\n5. Open Docker from your Applications folder (or Spotlight: Cmd+Space, type \"Docker\")\n6. macOS will ask for your password to grant permissions --- enter it\n7. If you see a \"Service Agreement\" screen, click **Accept**\n8. You can skip/close the tutorial and sign-in prompts --- you do NOT need a Docker account\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 5--10 minutes (including download)\n:::\n\n**Step 2: Verify the Installation**\n\nOpen **Terminal** (Spotlight: Cmd+Space, type \"Terminal\"):\n\n```bash\ndocker --version\n```\n\nYou should see something like `Docker version 27.x.x`. Now test:\n\n```bash\ndocker run hello-world\n```\n\nYou should see `Hello from Docker!`. If so, Docker is working.\n\n:::\n\n## Adjusting Docker Resources (Docker Desktop)\n\nBy default, Docker Desktop may allocate limited resources to containers. For running AI agents with R and Python, you should increase these limits:\n\n1. Open **Docker Desktop → Settings → Resources**\n2. Set:\n   - **CPUs:** At least 4 (or half of your total cores)\n   - **Memory:** At least 8 GB (ideally 12--16 GB)\n   - **Disk image size:** At least 60 GB\n3. Click **\"Apply & restart\"**\n\n::: {.callout-note}\nThese are *upper limits* --- Docker will not use these resources unless a container needs them. Your other applications will still run normally.\n:::\n\n---\n\n## Option B: Docker Engine in WSL 2 Without Docker Desktop (Windows Only)\n\nIf you prefer a **lightweight, CLI-only** setup --- or if you want to avoid Docker Desktop entirely --- you can install Docker Engine directly inside a WSL 2 Linux distribution. This is the most common Docker Desktop-free approach on Windows. You get the full `docker` and `docker compose` commands, but without the graphical interface.\n\n::: {.callout-tip collapse=\"true\"}\n## When to choose this option\n\n- You are comfortable working in a terminal and do not need a GUI\n- You want a smaller footprint (no background Desktop app running)\n- You are on a shared or restricted machine where installing Docker Desktop is not possible\n\n**Trade-offs:** You lose the Docker Desktop GUI and some convenience features (like automatic WSL integration across multiple distros, one-click resource settings, and the visual container dashboard). Functionally, however, everything works the same.\n:::\n\n**Step 1: Enable and Install WSL 2**\n\nIf you have not already installed WSL 2, open **PowerShell as Administrator** and run:\n\n```powershell\nwsl --install\n```\n\nRestart your computer when prompted. After restart, a window will ask you to create a Linux username and password.\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 5--10 minutes (including restart)\n:::\n\n**Step 2: Open Your WSL 2 Ubuntu Terminal**\n\nOpen **Ubuntu** from the Start menu. All the following commands are run inside this Linux terminal.\n\n**Step 3: Install Docker Engine**\n\nFollow the official Docker Engine installation steps for Ubuntu. Run these commands one by one:\n\n```bash\n# Update package index and install prerequisites\nsudo apt-get update\nsudo apt-get install -y ca-certificates curl\n\n# Add Docker's official GPG key\nsudo install -m 0755 -d /etc/apt/keyrings\nsudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg \\\n  -o /etc/apt/keyrings/docker.asc\nsudo chmod a+r /etc/apt/keyrings/docker.asc\n\n# Add Docker's repository\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] \\\n  https://download.docker.com/linux/ubuntu \\\n  $(. /etc/os-release && echo \"$VERSION_CODENAME\") stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n\n# Install Docker Engine and Docker Compose plugin\nsudo apt-get update\nsudo apt-get install -y docker-ce docker-ce-cli containerd.io \\\n  docker-buildx-plugin docker-compose-plugin\n```\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 5--10 minutes\n:::\n\n**Step 4: Start the Docker Daemon**\n\nWSL 2 does not use `systemd` by default, so Docker does not start automatically. You need to start it manually:\n\n```bash\nsudo service docker start\n```\n\nYou will need to run this command every time you open a new WSL terminal session (or after a reboot). To make it start automatically, add the following line to your `~/.bashrc` file:\n\n```bash\necho 'sudo service docker start' >> ~/.bashrc\n```\n\n::: {.callout-tip}\n## Avoid the sudo password prompt\nTo avoid the `sudo` password prompt every time Docker starts, you can add your user to the `docker` group:\n\n```bash\nsudo usermod -aG docker $USER\n```\n\nThen close and re-open your Ubuntu terminal for the change to take effect. After that, you can run `docker` commands without `sudo`.\n:::\n\n**Step 5: Verify the Installation**\n\n```bash\ndocker --version\ndocker run hello-world\n```\n\nYou should see `Docker version 27.x.x` and then `Hello from Docker!`. If so, Docker Engine is working inside your WSL 2 environment.\n\n::: {.callout-note}\n**From here, everything else in this guide works the same** --- all `docker buildx build`, `docker compose`, and `docker run` commands work identically whether you use Docker Desktop or Docker Engine in WSL 2.\n:::\n\n---\n\n## Option C: Docker Engine on Linux (Ubuntu)\n\nIf you are running Ubuntu (or another Debian-based distribution) as your main operating system --- not inside WSL, but as a native Linux desktop or server --- you can install Docker Engine directly. No Docker Desktop or WSL needed.\n\n::: {.callout-tip collapse=\"true\"}\n## When to choose this option\n\n- You are running Ubuntu 22.04, 24.04, or a similar Debian-based distribution as your primary OS\n- You are comfortable with the terminal\n- You want the most lightweight and direct Docker setup possible\n\n**Trade-offs:** No graphical dashboard. Resource limits are managed via `docker-compose.yml` or command-line flags rather than a GUI.\n:::\n\n**Step 1: Remove old Docker packages (if any)**\n\nIf you have previously installed Docker from Ubuntu's default repositories, remove them first to avoid conflicts:\n\n```bash\nsudo apt-get remove -y docker docker-engine docker.io containerd runc 2>/dev/null\n```\n\nThis is safe to run even if none of these packages are installed.\n\n**Step 2: Set up Docker's official repository**\n\n```bash\n# Update package index and install prerequisites\nsudo apt-get update\nsudo apt-get install -y ca-certificates curl\n\n# Add Docker's official GPG key\nsudo install -m 0755 -d /etc/apt/keyrings\nsudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg \\\n  -o /etc/apt/keyrings/docker.asc\nsudo chmod a+r /etc/apt/keyrings/docker.asc\n\n# Add Docker's repository\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] \\\n  https://download.docker.com/linux/ubuntu \\\n  $(. /etc/os-release && echo \"$VERSION_CODENAME\") stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n```\n\n**Step 3: Install Docker Engine**\n\n```bash\nsudo apt-get update\nsudo apt-get install -y docker-ce docker-ce-cli containerd.io \\\n  docker-buildx-plugin docker-compose-plugin\n```\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 3--5 minutes\n:::\n\n**Step 4: Allow your user to run Docker without sudo**\n\n```bash\nsudo usermod -aG docker $USER\n```\n\n**Log out and log back in** (or reboot) for this to take effect. After that, you can run `docker` commands without `sudo`.\n\n**Step 5: Verify the Installation**\n\n```bash\ndocker --version\ndocker run hello-world\n```\n\nYou should see `Docker version 27.x.x` and then `Hello from Docker!`.\n\n::: {.callout-note}\nOn a native Linux system, Docker Engine starts automatically via `systemd`. You do **not** need to start it manually (unlike in WSL 2). If it is not running, use:\n\n```bash\nsudo systemctl start docker\nsudo systemctl enable docker\n```\n:::\n\n::: {.callout-note}\n**From here, everything else in this guide works the same.** All `docker buildx build`, `docker compose`, and `docker run` commands work identically regardless of your operating system.\n:::\n\n---\n\n# Part 3: Understanding the Dockerfile\n\nBefore building our container, let us look at what goes inside the Dockerfile. You do not have to write this yourself --- we provide a ready-made Dockerfile. But understanding it helps you know what is happening.\n\nA Dockerfile is just a text file called `Dockerfile` (no extension) that lists instructions. Each instruction adds a \"layer\" to the image. Here is a simplified overview of what our Dockerfile does:\n\n```\n1. Start from a base Linux image (Ubuntu 24.04)\n2. Install system tools (curl, wget, git, build tools, LaTeX)\n3. Install R and R packages\n4. Install Python and Python packages\n5. Install Node.js (needed for Codex and Gemini CLI)\n6. Install Claude Code\n7. Install OpenAI Codex\n8. Install Google Gemini CLI\n9. Set up working directories\n```\n\n## Installing R Inside the Container\n\nOur Dockerfile adds the official CRAN repository for Ubuntu to get the latest stable R version, then installs R and common packages:\n\n```dockerfile\n# Add the CRAN repository for the latest R version\nRUN wget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | \\\n        tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc && \\\n    add-apt-repository \\\n        \"deb https://cloud.r-project.org/bin/linux/ubuntu noble-cran40/\"\n\n# Install R and system libraries needed by R packages\nRUN apt-get update && apt-get install -y r-base r-base-dev\n\n# Install R packages\nRUN Rscript -e \"install.packages(c('tidyverse', 'fixest', 'modelsummary', \\\n    'haven', 'data.table', 'rmarkdown'), \\\n    repos='https://cloud.r-project.org')\"\n```\n\n::: {.callout-tip}\nInstalling many R packages takes time. Our Dockerfile pre-installs \\~80 econometrics packages so you do not have to wait during the workshop.\n:::\n\n## Installing Python Inside the Container\n\n```dockerfile\n# Example: Installing Python with a virtual environment\nRUN apt-get install -y python3 python3-pip python3-venv\nRUN python3 -m venv /opt/venv\nENV PATH=\"/opt/venv/bin:$PATH\"\n\n# Install Python packages\nRUN pip install numpy pandas matplotlib jupyter\n```\n\n## Installing Stata Inside the Container (Special Case)\n\nUnlike R and Python, **Stata is commercial software**. You cannot freely download and install it. There are three options:\n\n**Option A: Use your university's Stata license (recommended if available)**\n\nIf your university provides a Stata license, you can install it inside the container. You will need:\n\n1. The Stata installer file (e.g., `Stata18Linux64.tar.gz`) --- ask your IT department\n2. Your license information (serial number, code, authorization)\n\n```dockerfile\n# Copy the Stata installer into the container\nCOPY Stata18Linux64.tar.gz /tmp/\nRUN cd /tmp && tar -xzf Stata18Linux64.tar.gz && \\\n    cd /tmp/Stata18 && ./install\n\n# You will need to initialize the license separately after the container starts:\n# Inside the container, run: stata -q -e \"exit\"\n# and enter your license details when prompted\n```\n\n::: {.callout-important}\nStata for Linux is different from Stata for Windows/Mac. Even if you have Stata on your laptop, you need a **Linux version** for the Docker container. Some university licenses include all platforms.\n:::\n\n**Option B: Mount Stata from your host system**\n\nIf you have Stata installed on your Mac/Windows machine, you can \"share\" it into the container using a Docker volume. This is more complex and depends on your specific Stata installation path.\n\n**Option C: Skip Stata and use R equivalents**\n\nFor many econometric analyses, R packages like `fixest`, `plm`, `ivreg`, and `rdrobust` can replicate Stata functionality. The workshop's CLAUDE.md includes a complete Stata-to-R mapping table for this purpose. This is the easiest option if you do not have a Linux Stata license.\n\n## Installing Node.js (Required for Codex and Gemini CLI)\n\nOpenAI Codex and Google Gemini CLI require Node.js. Claude Code uses a native binary installer and does not depend on Node.js.\n\n```dockerfile\n# Install Node.js 24 LTS\nRUN curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | \\\n        gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg && \\\n    echo \"deb [signed-by=/etc/apt/keyrings/nodesource.gpg] \\\n        https://deb.nodesource.com/node_24.x nodistro main\" | \\\n        tee /etc/apt/sources.list.d/nodesource.list > /dev/null && \\\n    apt-get update && apt-get install -y nodejs\n```\n\n---\n\n# Part 4: Building the Docker Image\n\nNow we will actually build the image. This is where Docker reads the Dockerfile and creates the frozen environment.\n\n**Step 1: Download the workshop files**\n\nOpen your terminal (Ubuntu on Windows, Terminal on Mac/Linux) and download or clone the workshop repository:\n\n```bash\n# Navigate to your home directory\ncd ~\n\n# Clone the workshop repository\ngit clone https://github.com/AlexRieber/Workshops.git\n\n# Enter the Docker workshop directory\ncd Workshops/Docker\n```\n\n::: {.callout-tip}\nIf you received the files as a ZIP, unzip them and navigate to the folder using `cd`.\n:::\n\n**Step 2: Build the image**\n\n```bash\ndocker buildx build -t coding-agent .\n```\n\nBreaking this command down:\n\n| Part | Meaning |\n|------|---------|\n| `docker buildx build` | Tell Docker to build an image |\n| `-t coding-agent` | Name the image `coding-agent` (you can choose any name) |\n| `.` | Look for the Dockerfile in the current directory |\n\n::: {.callout-note}\n## Build time: 20--30 minutes\nThe first build takes 20--30 minutes. Docker has to download the base image, install all system packages, compile R packages, etc.\n\n**Good news:** Docker *caches* every step. If you change only the CLAUDE.md file (for example) and rebuild, it takes seconds because Docker reuses the cached layers for everything else.\n:::\n\n**What to expect during the build:**\n\n- You will see lots of text scrolling by --- that is normal\n- Lines starting with `#6 [3/12] RUN apt-get...` show progress through the build steps\n- Warnings about deprecated package versions are usually harmless\n- If the build fails, read the last few lines of error output --- they usually tell you what went wrong\n\n**Step 3: Verify the image was created**\n\n```bash\ndocker images\n```\n\nYou should see `coding-agent` in the list with a size of several gigabytes.\n\n---\n\n# Part 5: Running the Container\n\n## Starting the Container (Simple Version)\n\nFor a quick start, run:\n\n```bash\ndocker run -it \\\n  --name my-agent \\\n  -v \"$(pwd)/workspace\":/home/agent/project \\\n  -v \"$(pwd)/output\":/home/agent/output \\\n  coding-agent \\\n  bash\n```\n\nThis command:\n\n| Part | What It Does |\n|------|--------------|\n| `docker run -it` | Start a new container in interactive mode (you can type commands) |\n| `--name my-agent` | Give the container a name so you can refer to it later |\n| `-v \"$(pwd)/workspace\":/home/agent/project` | Share the `workspace/` folder between your computer and the container |\n| `-v \"$(pwd)/output\":/home/agent/output` | Share the `output/` folder for results |\n| `coding-agent` | Use the image we built |\n| `bash` | Open a bash shell inside the container |\n\nYou are now *inside* the container. Your prompt changes to something like `root@a1b2c3d4:/home/agent#`.\n\n::: {.callout-tip}\nThe `workspace/` and `output/` folders are shared between the container and your computer. Anything the AI agent saves there, you can see on your host system. Everything else inside the container is isolated.\n:::\n\n## Starting the Container (Recommended: with Resource Limits)\n\nFor a more controlled setup, use `docker compose`. Create a file called `docker-compose.yml` in your project directory:\n\n```yaml\nservices:\n  agent:\n    image: coding-agent\n    container_name: my-agent\n    stdin_open: true\n    tty: true\n    mem_limit: 16g\n    memswap_limit: 16g\n    cpus: 4\n    pids_limit: 512\n    volumes:\n      - ./workspace:/home/agent/project\n      - ./output:/home/agent/output\n      - ./CLAUDE.md:/home/agent/CLAUDE.md:ro\n      - agent-auth:/root/.claude\n    working_dir: /home/agent\n\nvolumes:\n  agent-auth:\n```\n\nThen run:\n\n```bash\n# Create the shared folders if they do not exist\nmkdir -p workspace output\n\n# Start the container in the background\ndocker compose up -d\n\n# Enter the running container\ndocker exec -it my-agent bash\n```\n\n## What Are Resource Limits and Why?\n\n| Setting | Value | Purpose |\n|---------|-------|---------|\n| `mem_limit: 16g` | Max 16 GB RAM | Prevents the agent from using all your computer's memory |\n| `memswap_limit: 16g` | No swap allowed | Prevents slow-down from excessive swapping |\n| `cpus: 4` | Max 4 CPU cores | Leaves CPU capacity for your other applications |\n| `pids_limit: 512` | Max 512 processes | Prevents runaway process creation (fork bombs) |\n\n## Exiting and Re-entering the Container\n\n```bash\n# To leave the container (it keeps running):\nexit\n\n# To re-enter a running container:\ndocker exec -it my-agent bash\n\n# To stop the container:\ndocker compose down\n\n# To start it again later:\ndocker compose up -d\n```\n\n---\n\n# Part 6: Setting Up Claude Code\n\nClaude Code is Anthropic's terminal-based AI coding agent. It reads files, writes code, runs commands, and iterates on errors --- all from the command line. There are two ways to authenticate.\n\n## Option A: Anthropic API Key (Pay-per-use)\n\nThis option charges you per token (per amount of text processed). You control your spending through the API dashboard.\n\n**Step 1: Get an API key**\n\n1. Go to: **[https://platform.claude.com/](https://platform.claude.com/)**\n2. Create an account (or sign in)\n3. Go to **\"API Keys\"** in the left sidebar\n4. Click **\"Create Key\"**, give it a name (e.g., \"workshop\"), and copy the key\n5. **Important:** The key starts with `sk-ant-...`. Save it somewhere safe --- you will not be able to see it again.\n6. Add credit to your account under **\"Billing\"** (even $5--10 is enough for a workshop session)\n\n**Step 2: Install Claude Code inside the container**\n\nOur Dockerfile already includes Claude Code. If you need to install it manually:\n\n```bash\n# Inside the container:\ncurl -fsSL https://claude.ai/install.sh | bash\n```\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 1--2 minutes\n:::\n\n**Step 3: Authenticate with the API key**\n\n```bash\n# Inside the container, set the API key:\nexport ANTHROPIC_API_KEY=\"sk-ant-your-key-here\"\n\n# Start Claude Code:\nclaude\n```\n\nClaude Code will detect the API key and start immediately.\n\n::: {.callout-tip}\nTo avoid re-entering the key every time, add it to the container's shell profile:\n\n```bash\necho 'export ANTHROPIC_API_KEY=\"sk-ant-your-key-here\"' >> ~/.bashrc\n```\n:::\n\n## Option B: Claude Max Subscription (Fixed Monthly Cost)\n\nIf you have a Claude Pro ($20/month) or Max ($100 or $200/month) subscription, you can use Claude Code without API charges. Usage counts against your subscription's rate limits.\n\n**Step 1: Get a subscription**\n\n1. Go to: **[https://claude.ai/](https://claude.ai/)**\n2. Sign up or sign in\n3. Upgrade to Pro or Max under account settings\n\n**Step 2: Authenticate inside the container**\n\n```bash\n# Inside the container:\nclaude\n```\n\nClaude Code will display a message like:\n\n```\nTo authenticate, visit:\nhttps://claude.ai/login?code=ABCD-1234-EFGH\n```\n\n1. **Copy** the URL from the terminal\n2. **Open** the URL in a web browser on your host machine (your laptop)\n3. Sign in with your Claude account\n4. Click **\"Authorize\"**\n5. Back in the terminal, you should see: `Authenticated successfully!`\n\n::: {.callout-note}\n**The login is saved.** If you used `docker-compose.yml` with the `agent-auth` volume (as shown above), your login persists even if you stop, remove, and recreate the container. You only need to log in once.\n:::\n\n## Verifying Claude Code Works\n\nAfter authentication (either method), test it:\n\n```bash\nclaude --version\n```\n\nThen start an interactive session:\n\n```bash\nclaude\n```\n\nYou should see the Claude Code interface. Type a simple test message like `What is 2+2?` and press Enter. If you get a response, everything is working.\n\n## Running Claude Code with Specific Models\n\n```bash\n# Use the default model (Sonnet):\nclaude\n\n# Use the most capable model (Opus --- requires Max $200 or API):\nclaude --model opus\n\n# See real-time thinking (recommended for learning):\nclaude --verbose\n```\n\n---\n\n# Part 7: Setting Up OpenAI Codex\n\nOpenAI Codex is OpenAI's terminal-based AI coding agent, similar in concept to Claude Code. It is open source (Apache 2.0 license) and available on GitHub at [https://github.com/openai/codex](https://github.com/openai/codex).\n\n## Authentication Options for Codex\n\nLike Claude Code, Codex supports two authentication methods:\n\n| Method | What You Need | Cost Model |\n|--------|---------------|------------|\n| **OpenAI API Key** | API key from platform.openai.com | Pay-per-token |\n| **ChatGPT Subscription** | ChatGPT Plus, Pro, or Enterprise plan | Included in subscription |\n\n::: {.callout-important}\nThe ChatGPT subscription login uses a browser-based OAuth flow that opens a local web server on port 1455. This is difficult to use from inside a Docker container. For Docker setups, **we recommend using an API key**.\n:::\n\n## Step 1: Get an OpenAI API Key\n\n1. Go to: **[https://platform.openai.com/](https://platform.openai.com/)**\n2. Create an account (or sign in)\n3. Go to **\"API Keys\"** in the sidebar\n4. Click **\"Create new secret key\"**, give it a name, and copy the key\n5. The key starts with `sk-...`. Save it somewhere safe.\n6. Add credit under **\"Billing\"** (again, $5--10 is plenty for experimenting)\n\n## Step 2: Install Codex Inside the Container\n\nOur Dockerfile already includes Codex. If you need to install it manually:\n\n```bash\n# Inside the container:\nnpm install -g @openai/codex\n```\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 1--2 minutes\n:::\n\n## Step 3: Authenticate and Run\n\n```bash\n# Set the API key:\nexport OPENAI_API_KEY=\"sk-your-key-here\"\n\n# Start Codex interactively:\ncodex\n```\n\nFor **non-interactive** use (e.g., in scripts), Codex provides the `exec` subcommand:\n\n```bash\ncodex exec \"analyze the data in data.csv and create a summary\"\n```\n\n## Step 4: Useful Codex Flags\n\n| Flag | What It Does |\n|------|--------------|\n| `--full-auto` | Agent applies changes without asking for approval |\n| `--sandbox danger-full-access` | Disable sandboxing (appropriate when already in Docker) |\n| `--model <name>` | Choose which OpenAI model to use (e.g., `o3-mini`) |\n\n::: {.callout-note}\n**Note on sandboxing:** Codex has its own built-in sandbox (using Linux Landlock on Linux). Since we are already running inside a Docker container (which is itself a sandbox), you can safely use `--sandbox danger-full-access` to avoid sandboxing conflicts. The Docker container provides the isolation.\n:::\n\n---\n\n# Part 8: Setting Up Google Gemini CLI\n\nGoogle Gemini CLI is Google's open-source terminal-based AI coding agent (Apache 2.0 license), available on GitHub at [https://github.com/google-gemini/gemini-cli](https://github.com/google-gemini/gemini-cli). It provides access to Gemini models with a 1M token context window.\n\n## Authentication Options for Gemini CLI\n\n| Method | What You Need | Cost Model |\n|--------|---------------|------------|\n| **Google AI Studio API Key** | API key from aistudio.google.com | Free tier (limits vary by model) |\n| **Google Account Login** | Personal Google account | Free (same limits as above) |\n| **Vertex AI** | Google Cloud project with billing | Pay-per-token |\n\n## Option A: Google AI Studio API Key (Recommended)\n\n**Step 1: Get an API key**\n\n1. Go to: **[https://aistudio.google.com/](https://aistudio.google.com/)**\n2. Sign in with your Google account\n3. Click **\"Get API key\"** → **\"Create API key\"**\n4. Copy the key and save it somewhere safe\n\n::: {.callout-tip}\nThe free tier is generous for the default model (Gemini Flash). Limits vary by model --- more capable models like Gemini Pro have lower quotas. Either way, the free tier is more than enough for a workshop session without spending any money.\n:::\n\n**Step 2: Install Gemini CLI inside the container**\n\nOur Dockerfile already includes Gemini CLI. If you need to install it manually:\n\n```bash\n# Inside the container:\nnpm install -g @google/gemini-cli\n```\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 1--2 minutes\n:::\n\n**Step 3: Authenticate with the API key**\n\n```bash\n# Inside the container, set the API key:\nexport GEMINI_API_KEY=\"your-key-here\"\n\n# Start Gemini CLI:\ngemini\n```\n\n## Option B: Google Account Login (No API Key Needed)\n\nIf you prefer not to create an API key, Gemini CLI can authenticate directly with your Google account:\n\n```bash\n# Inside the container:\ngemini\n```\n\nOn first run, Gemini CLI will display a URL. Open it in your browser, sign in with your Google account, and authorize the application. The same free tier limits apply.\n\n::: {.callout-important}\nThe browser login flow requires network access from the container. If you are on a restricted network, use the API key method instead.\n:::\n\n## Verifying Gemini CLI Works\n\n```bash\ngemini --version\n```\n\nThen start an interactive session:\n\n```bash\ngemini\n```\n\nType a test message. If you get a response, everything is working.\n\n---\n\n# Part 9: The Complete Dockerfile {#part-9}\n\nThe complete Dockerfile is available in the workshop repository:\n\n**[`Dockerfile` on GitHub](https://github.com/AlexRieber/Workshops/blob/main/Docker/Dockerfile)**\n\nIf you cloned the repository (see Part 4), you already have this file. Otherwise, download it directly and place it in your project directory as `Dockerfile` (no file extension).\n\nHere is what each section of the Dockerfile does:\n\n| Layer | What It Does |\n|-------|--------------|\n| **Base image** (`FROM ubuntu:24.04`) | Starts from a clean Ubuntu 24.04 LTS Linux system |\n| **System tools** | Installs `curl`, `wget`, `git`, `nano`, `jq`, `tree`, build tools, and LaTeX (for rendering R Markdown / Quarto documents) |\n| **R + R packages** | Adds the CRAN repository for the latest stable R, then installs R plus \\~25 core econometrics and data science packages (tidyverse, fixest, modelsummary, haven, etc.). This is the slowest step (\\~10--15 min). |\n| **Python + packages** | Installs Python 3 in a virtual environment with `numpy`, `pandas`, `matplotlib`, and `jupyter` |\n| **AI provider SDKs** | Installs the `openai`, `anthropic`, and `google-genai` Python SDKs for building custom agents |\n| **Aider** | Open-source AI coding agent with built-in OpenRouter support (use any model) |\n| **Agent utilities** | `rich` (terminal formatting), `prompt_toolkit` (interactive input), `pydantic` (structured data) |\n| **Node.js 24 LTS** | Required runtime for OpenAI Codex and Google Gemini CLI |\n| **Claude Code** | Anthropic's terminal-based coding agent (native binary, does not require Node.js) |\n| **OpenAI Codex** | OpenAI's terminal-based coding agent |\n| **Google Gemini CLI** | Google's terminal-based coding agent |\n| **Working directories** | Creates the folder structure (`project/`, `output/`, `data/`, `code/`) |\n| **CMD** | Sets `bash` as the default command when the container starts |\n\n::: {.callout-tip}\n## Customizing the Dockerfile for your needs\n\nThe provided Dockerfile is a starting point. You will likely want to adapt it to your own research workflow --- for example, adding specific R or Python packages, additional system libraries, or different tools.\n\n**Ask your preferred LLM to help you.** Copy the Dockerfile into a chat with ChatGPT, Claude, Gemini, or whichever model you prefer and describe what you need:\n\n- *\"I need to add the `sf` and `terra` R packages for geospatial analysis. What system libraries do I need and how should I modify this Dockerfile?\"*\n- *\"I want to add Julia to this container. What lines should I add?\"*\n- *\"I work with LaTeX documents using Biblatex. What do I need to add?\"*\n\nLLMs are excellent at writing and debugging Dockerfiles. They can suggest the right `apt-get` packages, handle dependency chains, and help you keep the image size manageable. This is a great way to learn Docker syntax while getting a setup tailored to your needs.\n:::\n\n::: {.callout-note}\n## Build time expectations\n\n| Step | Approximate Time |\n|------|-----------------|\n| Download base image | 1--2 min |\n| System tools + LaTeX | 3--5 min |\n| R + R packages | 10--15 min |\n| Python + packages | 2--3 min |\n| Node.js + Claude Code + Codex + Gemini CLI | 3--5 min |\n| **Total (first build)** | **\\~20--30 min** |\n| **Rebuild after changing only CLAUDE.md** | **< 10 seconds** |\n:::\n\n---\n\n# Part 10: Putting It All Together (Full Walkthrough)\n\nHere is the complete process from zero to a running agent. Follow these steps in order.\n\n## 1. Install Docker (\\~10 min)\n\n- **Windows:** Follow Part 2, Option A (install WSL 2, then Docker Desktop) or Option B (Docker Engine in WSL 2)\n- **Mac:** Follow Part 2, Option A (download and install Docker Desktop)\n- **Linux:** Follow Part 2, Option C (install Docker Engine directly)\n- Verify with `docker run hello-world`\n\n## 2. Create Your Project Folder (\\~2 min)\n\nOpen your terminal (Ubuntu on Windows, Terminal on Mac/Linux):\n\n```bash\nmkdir -p ~/coding-agent-workshop\ncd ~/coding-agent-workshop\nmkdir -p workspace output\n```\n\n## 3. Get the Dockerfile (\\~2 min)\n\nIf you cloned the repository in step 1 of Part 4, the `Dockerfile` is already included. Otherwise, download it from the [workshop repository on GitHub](https://github.com/AlexRieber/Workshops/blob/main/Docker/Dockerfile) and save it as `Dockerfile` (no extension) in `~/coding-agent-workshop/`. On the command line, you can open the folder:\n\n::: {.os-compare}\n\n::: {.windows}\nOpen the folder in Explorer:\n\n```bash\nexplorer.exe $(wslpath -w ~/coding-agent-workshop)\n```\n:::\n\n::: {.mac}\nOpen the folder in Finder:\n\n```bash\nopen ~/coding-agent-workshop\n```\n:::\n\n:::\n\nThen place the `Dockerfile` (no extension!) in this folder.\n\n## 4. Create the docker-compose.yml (\\~1 min)\n\nCreate `docker-compose.yml` in the same folder with the content from Part 5.\n\n## 5. Build the Image (\\~20--30 min)\n\n```bash\ncd ~/coding-agent-workshop\ndocker buildx build -t coding-agent .\n```\n\nGo get a coffee. This will take a while the first time.\n\n## 6. Start the Container (\\~10 sec)\n\n```bash\ndocker compose up -d\ndocker exec -it my-agent bash\n```\n\nYou are now inside the container.\n\n## 7. Verify Everything Is Installed (\\~1 min)\n\nInside the container, run:\n\n```bash\n# Check R\nR --version | head -1\n\n# Check Python\npython3 --version\n\n# Check Node.js\nnode --version\n\n# Check Claude Code\nclaude --version\n\n# Check Codex\ncodex --version\n\n# Check Gemini CLI\ngemini --version\n\n# Check Aider\naider --version\n```\n\nAll commands should print a version number.\n\n## 8. Authenticate Your AI Agent (\\~2 min)\n\n**For Claude Code:**\n\n```bash\n# Option A: API key\nexport ANTHROPIC_API_KEY=\"sk-ant-your-key-here\"\nclaude\n\n# Option B: Max subscription\nclaude\n# Follow the browser login flow (see Part 6)\n```\n\n**For OpenAI Codex:**\n\n```bash\nexport OPENAI_API_KEY=\"sk-your-key-here\"\ncodex\n```\n\n**For Google Gemini CLI:**\n\n```bash\nexport GEMINI_API_KEY=\"your-key-here\"\ngemini\n```\n\n## 9. Start Working\n\nYou are ready! Give the agent a task:\n\n```bash\n# Claude Code (interactive):\nclaude\n\n# Or with verbose output to see its reasoning:\nclaude --verbose\n```\n\n---\n\n# Part 11: Everyday Commands (Cheat Sheet)\n\n## Starting and Stopping\n\n```bash\n# Start the container (from your project folder)\ndocker compose up -d\n\n# Enter the container\ndocker exec -it my-agent bash\n\n# Leave the container (it keeps running)\nexit\n\n# Stop the container\ndocker compose down\n```\n\n## Inside the Container\n\n```bash\n# Start Claude Code\nclaude\n\n# Start Claude Code with Opus model and verbose output\nclaude --model opus --verbose\n\n# Start OpenAI Codex\ncodex\n\n# Start Google Gemini CLI\ngemini\n\n# Start Aider with an OpenRouter model\nOPENROUTER_API_KEY=\"sk-or-...\" aider --model openrouter/moonshotai/kimi-k2\n\n# Run an R script\nRscript my_analysis.R\n\n# Start an interactive R session\nR\n\n# Start Python\npython3\n```\n\n## Managing Docker (on your host system)\n\n```bash\n# See running containers\ndocker ps\n\n# See all images\ndocker images\n\n# See resource usage of a running container\ndocker stats my-agent\n\n# Rebuild the image after changing the Dockerfile\ndocker buildx build -t coding-agent .\n\n# Remove the container (data in workspace/ and output/ is preserved)\ndocker rm -f my-agent\n\n# Remove the image (frees disk space)\ndocker rmi coding-agent\n\n# Nuclear option: remove everything Docker-related (containers, images, volumes)\n# WARNING: This deletes ALL Docker data, including saved authentication!\ndocker system prune -a --volumes\n```\n\n---\n\n# Part 12: Troubleshooting\n\n## Installation Problems\n\n| Problem | Solution |\n|---------|----------|\n| **Windows: \"WSL 2 installation is incomplete\"** | Open PowerShell as Admin, run `wsl --update`, restart |\n| **Windows: \"Hardware assisted virtualization is not enabled\"** | Enable VT-x/AMD-V in your BIOS settings (search for your laptop model + \"enable virtualization\") |\n| **Windows: Docker Desktop does not start** | Run `wsl --status` in PowerShell. If WSL is not running, try `wsl --shutdown` then restart Docker Desktop |\n| **Mac: \"Docker Desktop requires macOS 14 or later\"** | Update your macOS, or try an older version of Docker Desktop |\n| **`docker: command not found`** | Docker Desktop is not running, or the PATH is not set. Restart Docker Desktop. On Windows, make sure you are using the Ubuntu terminal. |\n\n## Build Problems\n\n| Problem | Solution |\n|---------|----------|\n| **Build fails at R package installation** | Some R packages need system libraries. Check the error message for missing `-dev` packages and add them to the `apt-get install` line in the Dockerfile |\n| **Build runs out of disk space** | Increase Docker Desktop's disk image size (Settings → Resources) and run `docker system prune` to free space |\n| **Build is very slow** | First builds are always slow. Subsequent rebuilds use cached layers and are much faster |\n| **\"network error\" during build** | Check your internet connection. Some corporate/university networks block Docker Hub. Try a different network or VPN. |\n\n## Runtime Problems\n\n| Problem | Solution |\n|---------|----------|\n| **Container immediately exits** | Use `docker run -it ... bash` (the `-it` flags keep it interactive) |\n| **`claude`, `codex`, `gemini`, or `aider` command not found** | Rebuild the image: `docker buildx build -t coding-agent .` |\n| **Claude Code: \"Authentication required\"** | Follow the login steps in Part 6. For API key: check that `ANTHROPIC_API_KEY` is set (`echo $ANTHROPIC_API_KEY`) |\n| **Codex: \"API key not found\"** | Check that `OPENAI_API_KEY` is set (`echo $OPENAI_API_KEY`) |\n| **Gemini CLI: authentication error** | Follow login steps in Part 8. For API key: check that `GEMINI_API_KEY` is set (`echo $GEMINI_API_KEY`) |\n| **\"No space left on device\" in container** | The container's disk is full. Remove unnecessary files, or increase Docker's disk image size |\n| **Everything is very slow** | Check Docker Desktop resource settings (Part 2). Give Docker more RAM and CPUs. On Windows: make sure files are in the WSL filesystem (`~/...`), not in `/mnt/c/...` |\n| **Lost authentication after container restart** | Make sure you are using the `agent-auth` volume in `docker-compose.yml` (see Part 5). Without it, auth is lost when the container is removed. |\n\n---\n\n# Part 13: Security and Isolation\n\nRunning an AI coding agent means giving software the ability to read files, write files, run commands, and access the internet. This section explains how Docker keeps you safe, and how to add extra layers of protection.\n\n## What the Container CAN Do\n\n- Read and write files inside the container\n- Access files in the mounted `workspace/` and `output/` folders\n- Make network requests (download data, call APIs)\n- Install software inside the container\n\n## What the Container CANNOT Do\n\n- Access files on your host system outside of the mounted folders\n- Modify your operating system or installed software\n- Access other running applications on your computer\n- Persist changes (except in mounted volumes) after being deleted\n\n## Best Practices\n\n1. **Never put sensitive files** (passwords, private keys, personal data) in the `workspace/` or `output/` folders\n2. **Review output** before sharing it --- AI agents can sometimes include unexpected content\n3. **Use resource limits** (as shown in the `docker-compose.yml`) to prevent runaway resource usage\n4. **Store API keys carefully** --- do not commit them to Git repositories. Use environment variables.\n5. **Regularly stop containers** you are not using --- they consume system resources even when idle\n\n---\n\n# Part 14: Advanced Safety --- Isolating Docker on Its Own Partition\n\n## Why a Separate Partition?\n\nBy default, Docker stores all its data (images, containers, volumes) on your main system drive. An autonomous AI agent could, in theory:\n\n- Download very large datasets, filling up your disk\n- Create many intermediate files during analysis\n- Pull additional Docker images\n\nIf your main drive runs out of space, your **entire system** can become unstable --- not just the container. The solution is to give Docker its own, separate storage area with a hard size limit. If that area fills up, Docker stops working but your operating system and personal files stay safe.\n\nThink of it like giving someone a dedicated filing cabinet rather than access to your entire office. When the cabinet is full, they cannot fill up anything else.\n\n## Option A: Move Docker Desktop's Storage (Recommended --- Easiest)\n\nThis is the simplest approach and works well for most students.\n\n::: {.windows}\n\n### Windows\n\nDocker Desktop on Windows stores its data inside WSL 2. You can move this to a different drive:\n\n**Step 1:** Stop Docker Desktop (right-click the whale icon in the system tray, select \"Quit Docker Desktop\")\n\n**Step 2:** Open PowerShell as Administrator:\n\n```powershell\n# Stop WSL\nwsl --shutdown\n\n# Export the Docker data distribution to your target drive\nwsl --export docker-desktop-data D:\\DockerData\\docker-desktop-data.tar\n\n# Unregister the original (this removes it from your C: drive)\nwsl --unregister docker-desktop-data\n\n# Import it at the new location with a size you control\nwsl --import docker-desktop-data D:\\DockerData D:\\DockerData\\docker-desktop-data.tar\n\n# Clean up the export file\ndel D:\\DockerData\\docker-desktop-data.tar\n```\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 5--15 minutes depending on how much Docker data you already have.\n\nReplace `D:\\DockerData` with any folder on a drive with enough space. If you have an external SSD or a second internal drive, use that.\n:::\n\n::: {.callout-important}\nRecent versions of Docker Desktop (4.30+) may no longer create a separate `docker-desktop-data` WSL distribution. If the `wsl --export docker-desktop-data` command fails, use Docker Desktop's built-in setting instead: **Settings → Resources → Disk image location** and move the storage from there.\n:::\n\n**Step 3:** Restart Docker Desktop. All Docker operations now use the new location.\n\n:::\n\n::: {.mac}\n\n### Mac\n\nOn Mac, Docker Desktop stores its data in a single disk image file. You can control its location and size:\n\n1. Open **Docker Desktop → Settings → Resources → Disk image location**\n2. Click **\"Browse\"** and select a folder on a different volume or external drive\n3. Set the **\"Disk image size\"** to your desired limit (e.g., 60 GB)\n4. Click **\"Apply & restart\"**\n\nDocker will move its data to the new location. This may take a few minutes.\n\n:::\n\n## Option B: Create a Dedicated Disk Image (Advanced --- Maximum Isolation)\n\nThis approach creates a fixed-size virtual disk that Docker uses. When it fills up, Docker hits a wall but your system stays safe. This is ideal for running AI agents that you want to constrain strictly.\n\n::: {.windows}\n\n### Windows (WSL 2)\n\nOn Windows, Docker runs inside WSL 2, which already uses a virtual disk (`.vhdx` file). You can control its maximum size:\n\n**Step 1:** Stop Docker Desktop and WSL:\n\n```powershell\nwsl --shutdown\n```\n\n**Step 2:** Create a `.wslconfig` file in your Windows home directory (`C:\\Users\\YourName\\.wslconfig`) with:\n\n```ini\n[wsl2]\n# Limit WSL 2 resource usage\nmemory=8GB\nprocessors=4\nswap=0\n```\n\n::: {.callout-note}\nThis `.wslconfig` file limits WSL 2's memory and CPU usage but does **not** directly cap the virtual disk size. The virtual disk (`ext4.vhdx`) grows dynamically up to 256 GB by default. To shrink an existing one, you need to use `diskpart` in PowerShell --- this is more complex and not necessary for a fresh setup. For hard disk limits on Windows, use Option A (move Docker storage to a drive with limited free space) instead.\n:::\n\n**Step 3:** Restart WSL and Docker Desktop.\n\n:::\n\n::: {.mac}\n\n### Mac\n\nOn Mac, you can create a dedicated APFS or HFS+ disk image:\n\n**Step 1:** Open **Disk Utility** (Spotlight: Cmd+Space, type \"Disk Utility\")\n\n**Step 2:** Go to **File → New Image → Blank Image** and configure:\n\n| Setting | Value |\n|---------|-------|\n| **Name** | DockerWorkspace |\n| **Size** | 60 GB (or your preferred limit) |\n| **Format** | APFS |\n| **Partitions** | Single partition - GUID |\n| **Image Format** | sparse disk image (grows as needed, up to the size limit) |\n\n**Step 3:** Click **\"Save\"**. The disk image (`.sparseimage`) will be created.\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** < 1 minute\n:::\n\n**Step 4:** Double-click the `.sparseimage` file to mount it. It appears as a drive in Finder (e.g., `/Volumes/DockerWorkspace`).\n\n**Step 5:** Point Docker Desktop to this location:\n\n1. Open **Docker Desktop → Settings → Resources → Disk image location**\n2. Set it to `/Volumes/DockerWorkspace`\n3. Click **\"Apply & restart\"**\n\n**Step 6: After every reboot**, double-click the `.sparseimage` file to mount it before starting Docker Desktop. Or automate it by adding it to your Login Items (System Settings → General → Login Items → add the `.sparseimage` file).\n\n:::\n\n## Option C: Create a Size-Limited Workspace Folder (Simplest Extra Protection)\n\nIf options A and B feel too complex, you can simply limit the workspace folder that the container uses. This does not protect Docker's internal storage, but it does protect against the agent filling your drive with data files.\n\n::: {.os-compare}\n\n::: {.windows}\n```bash\n# Create a 30 GB disk image file\ndd if=/dev/zero of=~/agent_workspace.img \\\n   bs=1M count=30720 status=progress\n\n# Format it as a filesystem\nmkfs.ext4 ~/agent_workspace.img\n\n# Create the mount point and mount it\nmkdir -p ~/coding-agent-workshop/workspace\nsudo mount -o loop ~/agent_workspace.img \\\n     ~/coding-agent-workshop/workspace\nsudo chmod 777 ~/coding-agent-workshop/workspace\n```\n\nAfter every reboot, re-mount with:\n\n```bash\nsudo mount -o loop ~/agent_workspace.img \\\n     ~/coding-agent-workshop/workspace\n```\n:::\n\n::: {.mac}\n```bash\n# Create a 30 GB sparse disk image\nhdiutil create -size 30g -fs APFS \\\n  -volname AgentWorkspace \\\n  -type SPARSE ~/agent_workspace.sparseimage\n\n# Mount it\nhdiutil attach ~/agent_workspace.sparseimage\n\n# Now use /Volumes/AgentWorkspace as your\n# workspace in docker-compose.yml\n```\n:::\n\n:::\n\nThen update your `docker-compose.yml` to use this mounted volume:\n\n```yaml\nvolumes:\n  - /Volumes/AgentWorkspace:/home/agent/project   # Mac\n  # or for Windows/WSL:\n  # - ~/coding-agent-workshop/workspace:/home/agent/project\n```\n\n## Understanding Volume Mounts: How Host Folders Connect to the Container\n\nVolume mounts are the bridge between your computer and the container. They control what the agent can see and where results appear.\n\n```\nYour Computer (Host)              Docker Container\n====================              ================\n\n~/coding-agent-workshop/          /home/agent/\n├── workspace/  ←──── volume ────→  project/      (agent reads & writes here)\n├── output/     ←──── volume ────→  output/       (results appear here)\n├── CLAUDE.md   ←──── volume ────→  CLAUDE.md     (read-only instructions)\n│\n├── Dockerfile  (not mounted, only used during build)\n└── my-files/   (NOT visible to container --- stays private)\n```\n\n**Key rules:**\n\n- The agent can **only** access folders you explicitly mount with `-v` or `volumes:` in `docker-compose.yml`\n- Anything NOT mounted is invisible to the container\n- Mounts are bidirectional: changes inside the container appear on your host, and vice versa\n- Use `:ro` (read-only) to mount files the agent should read but not change (e.g., `CLAUDE.md:ro`)\n\n**Choosing your shared folder:** You decide where on your host the shared folder lives. Here is how to think about it:\n\n| What You Want | How to Set It Up |\n|---------------|------------------|\n| **Simple sharing** in your project folder | `-v ./workspace:/home/agent/project` (the default) |\n| **Shared folder on a different drive** | `-v /Volumes/ExternalSSD/agent-data:/home/agent/project` (Mac) or `-v /mnt/d/agent-data:/home/agent/project` (Windows/WSL) |\n| **Size-limited workspace** | Mount a disk image (see Option C above), then use that as the volume path |\n| **Read-only data sharing** | `-v ~/my-datasets:/home/agent/data:ro` --- agent can read your datasets but not modify them |\n| **Multiple shared folders** | Add multiple `-v` lines, each mapping a different host path to a different container path |\n\n## Summary: Picking Your Isolation Level\n\n| Level | Setup Effort | What It Protects | Recommended For |\n|-------|-------------|------------------|-----------------|\n| **Default Docker** (container only) | None | Agent cannot escape the container | Quick experiments, supervised sessions |\n| **Resource limits** (docker-compose.yml) | Low | Limits RAM, CPU, processes | All use cases (always recommended) |\n| **Size-limited workspace** (Option C) | Medium | Prevents agent from filling your disk with data | Longer autonomous sessions |\n| **Separate Docker storage** (Option A) | Medium | Keeps Docker data off your system drive | Regular Docker users |\n| **Dedicated disk image** (Option B) | High | Hard cap on ALL Docker storage | Maximum safety, unattended agents |\n\n::: {.callout-tip}\n## Our recommendation for the workshop\nUse the default Docker setup with resource limits (docker-compose.yml from Part 5). This provides excellent isolation with minimal setup. Add Option C (size-limited workspace) if you plan to let agents run for extended periods.\n:::\n\n---\n\n# Glossary\n\n| Term | Definition |\n|------|-----------|\n| **Container** | A running, isolated environment created from an image. Like a lightweight virtual machine. |\n| **Dockerfile** | A text file with instructions for building an image. |\n| **Image** | A frozen snapshot of an environment. Containers are created from images. |\n| **Volume** | A way to share data between your host system and a container, or to persist data across container restarts. |\n| **WSL 2** | Windows Subsystem for Linux --- lets you run Linux tools on Windows. Required by Docker Desktop on Windows. |\n| **API Key** | A secret string that authenticates you with an AI service. Like a password for the API. |\n| **Sandbox** | An isolated environment where software can run without affecting the rest of the system. |\n| **Terminal** | A text-based interface for running commands. \"Ubuntu\" app on Windows, \"Terminal\" app on Mac and Linux. |\n| **Shell** | The program that interprets your commands in the terminal (usually `bash` or `zsh`). |\n","srcMarkdownNoYaml":"\n\n::: {.callout-note appearance=\"simple\"}\n**Who is this for?** Students who have never used Docker before and want to set up a safe, reproducible environment for running AI coding agents (Claude Code, OpenAI Codex, Google Gemini CLI, and Aider) alongside R, Python, and Stata.\n\n**What you need:** A Windows, Mac, or Linux computer with at least 16 GB RAM and 80 GB free disk space.\n\n**Workshop materials:** All files (Dockerfile, docker-compose.yml, CLAUDE.md, this guide) are available at **[github.com/AlexRieber/Workshops/Docker](https://github.com/AlexRieber/Workshops/tree/main/Docker)**.\n:::\n\n---\n\n# Part 1: What is Docker and Why Do We Need It?\n\n## The Problem\n\nImagine you want to let an AI agent write and run code on your computer. That agent can:\n\n- Install software packages\n- Download files from the internet\n- Create, modify, and delete files\n- Run arbitrary shell commands\n\nLetting an AI do all that directly on your laptop is risky. It might accidentally delete important files, install conflicting software, or fill up your hard drive. And if something goes wrong, cleaning up the mess can be painful.\n\n## The Solution: A Sandbox\n\n**Docker** lets you create an isolated \"mini-computer\" (called a **container**) that runs inside your real computer. Think of it as a virtual room where the AI agent can work freely. If anything goes wrong, you simply delete the container and start fresh --- your actual system remains untouched.\n\n## Three Concepts You Need to Know\n\n| Concept | Analogy | What It Is |\n|---------|---------|------------|\n| **Dockerfile** | A recipe | A text file with instructions: \"Install R, install Python, install Claude Code, set up these folders...\" |\n| **Image** | A frozen meal | The result of following the recipe --- a snapshot of a complete environment, ready to use |\n| **Container** | The meal, heated up and on your plate | A running instance of the image where you actually work |\n\n## Why Docker for This Workshop?\n\n| Benefit | What It Means for You |\n|---------|-----------------------|\n| **Safety (sandbox)** | The AI agent cannot touch your files, your system, or your other software. Everything stays inside the container. |\n| **Reproducibility** | Every student gets the exact same environment. No more \"it works on my machine\" problems. |\n| **Easy cleanup** | Done with the project? Delete the container and image. Your system is clean again. |\n| **Portability** | Share the Dockerfile with a colleague and they can rebuild the exact same setup in minutes. |\n\n---\n\n# Part 2: Installing Docker\n\n## Option A: Docker Desktop (Recommended for Beginners)\n\nDocker Desktop is a free application that lets you run containers on Windows and Mac (and Linux, though most Linux users prefer Docker Engine directly). It provides a graphical interface and handles all the technical complexity behind the scenes.\n\n::: {.callout-tip}\n## Good news for students and educators\nDocker Desktop is **free for educational use**. Docker's subscription terms explicitly exempt educational institutions, so you can use Docker Desktop at university without any licensing concerns.\n:::\n\n::: {.windows}\n\n## Windows (with Docker Desktop)\n\n**Prerequisites:** Windows 10 version 2004 or higher, or Windows 11. You need administrator access.\n\n**Step 1: Enable WSL 2** (Windows Subsystem for Linux)\n\nWSL 2 lets Docker run a lightweight Linux kernel inside Windows. This is required.\n\n1. Open **PowerShell as Administrator** (right-click the Start button, select \"Terminal (Admin)\" or \"Windows PowerShell (Admin)\")\n2. Run:\n\n```powershell\nwsl --install\n```\n\n3. **Restart your computer** when prompted\n4. After restart, a window will open asking you to create a Linux username and password. Choose something simple you will remember (e.g., your first name as username). **This is NOT your Windows password** --- it is a new, separate password for the Linux subsystem.\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 5--10 minutes (including restart)\n:::\n\n**Step 2: Install Docker Desktop**\n\n1. Go to: **[https://www.docker.com/products/docker-desktop/](https://www.docker.com/products/docker-desktop/)**\n2. Click **\"Download for Windows\"**\n3. Run the downloaded installer (`Docker Desktop Installer.exe`)\n4. Keep all default settings and click through the installer\n5. When installation finishes, **restart your computer** if prompted\n6. Docker Desktop should start automatically after login. You will see a whale icon in your system tray (bottom-right).\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 5--10 minutes (including download)\n:::\n\n**Step 3: Configure Docker Desktop**\n\n1. Open Docker Desktop (click the whale icon in the system tray)\n2. If you see a \"Service Agreement\" screen, click **Accept**\n3. You can skip or close the tutorial/sign-in prompts --- you do NOT need a Docker account\n4. Go to **Settings** (gear icon, top-right):\n   - **General** tab: Make sure **\"Use the WSL 2 based engine\"** is checked (it usually is by default)\n   - **Resources → WSL Integration** tab: Toggle ON the switch next to your Ubuntu distribution\n   - Click **\"Apply & restart\"**\n\n**Step 4: Verify the Installation**\n\nOpen **Ubuntu** from your Start menu (NOT PowerShell, NOT CMD --- use the Ubuntu app that WSL installed):\n\n```bash\ndocker --version\n```\n\nYou should see something like `Docker version 27.x.x`. Now test that Docker can run containers:\n\n```bash\ndocker run hello-world\n```\n\nYou should see a message starting with `Hello from Docker!`. If so, Docker is working.\n\n::: {.callout-important}\nFrom now on, **always work in the Ubuntu/WSL terminal** for all Docker commands. Do not use PowerShell or CMD.\n:::\n\n:::\n\n::: {.mac}\n\n## Mac\n\n**Prerequisites:** macOS 14 (Sonoma) or later. You need administrator access. Check whether your Mac has an **Apple Silicon** chip (M1, M2, M3, M4) or an **Intel** chip: click the Apple menu, select \"About This Mac\", and look at the \"Chip\" line.\n\n**Step 1: Install Docker Desktop**\n\n1. Go to: **[https://www.docker.com/products/docker-desktop/](https://www.docker.com/products/docker-desktop/)**\n2. Click **\"Download for Mac\"**\n   - If you have Apple Silicon (M1/M2/M3/M4): select **\"Apple Silicon\"** (this is the default now)\n   - If you have Intel: select **\"Intel chip\"**\n3. Open the downloaded `.dmg` file\n4. Drag the Docker icon into your Applications folder\n5. Open Docker from your Applications folder (or Spotlight: Cmd+Space, type \"Docker\")\n6. macOS will ask for your password to grant permissions --- enter it\n7. If you see a \"Service Agreement\" screen, click **Accept**\n8. You can skip/close the tutorial and sign-in prompts --- you do NOT need a Docker account\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 5--10 minutes (including download)\n:::\n\n**Step 2: Verify the Installation**\n\nOpen **Terminal** (Spotlight: Cmd+Space, type \"Terminal\"):\n\n```bash\ndocker --version\n```\n\nYou should see something like `Docker version 27.x.x`. Now test:\n\n```bash\ndocker run hello-world\n```\n\nYou should see `Hello from Docker!`. If so, Docker is working.\n\n:::\n\n## Adjusting Docker Resources (Docker Desktop)\n\nBy default, Docker Desktop may allocate limited resources to containers. For running AI agents with R and Python, you should increase these limits:\n\n1. Open **Docker Desktop → Settings → Resources**\n2. Set:\n   - **CPUs:** At least 4 (or half of your total cores)\n   - **Memory:** At least 8 GB (ideally 12--16 GB)\n   - **Disk image size:** At least 60 GB\n3. Click **\"Apply & restart\"**\n\n::: {.callout-note}\nThese are *upper limits* --- Docker will not use these resources unless a container needs them. Your other applications will still run normally.\n:::\n\n---\n\n## Option B: Docker Engine in WSL 2 Without Docker Desktop (Windows Only)\n\nIf you prefer a **lightweight, CLI-only** setup --- or if you want to avoid Docker Desktop entirely --- you can install Docker Engine directly inside a WSL 2 Linux distribution. This is the most common Docker Desktop-free approach on Windows. You get the full `docker` and `docker compose` commands, but without the graphical interface.\n\n::: {.callout-tip collapse=\"true\"}\n## When to choose this option\n\n- You are comfortable working in a terminal and do not need a GUI\n- You want a smaller footprint (no background Desktop app running)\n- You are on a shared or restricted machine where installing Docker Desktop is not possible\n\n**Trade-offs:** You lose the Docker Desktop GUI and some convenience features (like automatic WSL integration across multiple distros, one-click resource settings, and the visual container dashboard). Functionally, however, everything works the same.\n:::\n\n**Step 1: Enable and Install WSL 2**\n\nIf you have not already installed WSL 2, open **PowerShell as Administrator** and run:\n\n```powershell\nwsl --install\n```\n\nRestart your computer when prompted. After restart, a window will ask you to create a Linux username and password.\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 5--10 minutes (including restart)\n:::\n\n**Step 2: Open Your WSL 2 Ubuntu Terminal**\n\nOpen **Ubuntu** from the Start menu. All the following commands are run inside this Linux terminal.\n\n**Step 3: Install Docker Engine**\n\nFollow the official Docker Engine installation steps for Ubuntu. Run these commands one by one:\n\n```bash\n# Update package index and install prerequisites\nsudo apt-get update\nsudo apt-get install -y ca-certificates curl\n\n# Add Docker's official GPG key\nsudo install -m 0755 -d /etc/apt/keyrings\nsudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg \\\n  -o /etc/apt/keyrings/docker.asc\nsudo chmod a+r /etc/apt/keyrings/docker.asc\n\n# Add Docker's repository\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] \\\n  https://download.docker.com/linux/ubuntu \\\n  $(. /etc/os-release && echo \"$VERSION_CODENAME\") stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n\n# Install Docker Engine and Docker Compose plugin\nsudo apt-get update\nsudo apt-get install -y docker-ce docker-ce-cli containerd.io \\\n  docker-buildx-plugin docker-compose-plugin\n```\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 5--10 minutes\n:::\n\n**Step 4: Start the Docker Daemon**\n\nWSL 2 does not use `systemd` by default, so Docker does not start automatically. You need to start it manually:\n\n```bash\nsudo service docker start\n```\n\nYou will need to run this command every time you open a new WSL terminal session (or after a reboot). To make it start automatically, add the following line to your `~/.bashrc` file:\n\n```bash\necho 'sudo service docker start' >> ~/.bashrc\n```\n\n::: {.callout-tip}\n## Avoid the sudo password prompt\nTo avoid the `sudo` password prompt every time Docker starts, you can add your user to the `docker` group:\n\n```bash\nsudo usermod -aG docker $USER\n```\n\nThen close and re-open your Ubuntu terminal for the change to take effect. After that, you can run `docker` commands without `sudo`.\n:::\n\n**Step 5: Verify the Installation**\n\n```bash\ndocker --version\ndocker run hello-world\n```\n\nYou should see `Docker version 27.x.x` and then `Hello from Docker!`. If so, Docker Engine is working inside your WSL 2 environment.\n\n::: {.callout-note}\n**From here, everything else in this guide works the same** --- all `docker buildx build`, `docker compose`, and `docker run` commands work identically whether you use Docker Desktop or Docker Engine in WSL 2.\n:::\n\n---\n\n## Option C: Docker Engine on Linux (Ubuntu)\n\nIf you are running Ubuntu (or another Debian-based distribution) as your main operating system --- not inside WSL, but as a native Linux desktop or server --- you can install Docker Engine directly. No Docker Desktop or WSL needed.\n\n::: {.callout-tip collapse=\"true\"}\n## When to choose this option\n\n- You are running Ubuntu 22.04, 24.04, or a similar Debian-based distribution as your primary OS\n- You are comfortable with the terminal\n- You want the most lightweight and direct Docker setup possible\n\n**Trade-offs:** No graphical dashboard. Resource limits are managed via `docker-compose.yml` or command-line flags rather than a GUI.\n:::\n\n**Step 1: Remove old Docker packages (if any)**\n\nIf you have previously installed Docker from Ubuntu's default repositories, remove them first to avoid conflicts:\n\n```bash\nsudo apt-get remove -y docker docker-engine docker.io containerd runc 2>/dev/null\n```\n\nThis is safe to run even if none of these packages are installed.\n\n**Step 2: Set up Docker's official repository**\n\n```bash\n# Update package index and install prerequisites\nsudo apt-get update\nsudo apt-get install -y ca-certificates curl\n\n# Add Docker's official GPG key\nsudo install -m 0755 -d /etc/apt/keyrings\nsudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg \\\n  -o /etc/apt/keyrings/docker.asc\nsudo chmod a+r /etc/apt/keyrings/docker.asc\n\n# Add Docker's repository\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] \\\n  https://download.docker.com/linux/ubuntu \\\n  $(. /etc/os-release && echo \"$VERSION_CODENAME\") stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n```\n\n**Step 3: Install Docker Engine**\n\n```bash\nsudo apt-get update\nsudo apt-get install -y docker-ce docker-ce-cli containerd.io \\\n  docker-buildx-plugin docker-compose-plugin\n```\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 3--5 minutes\n:::\n\n**Step 4: Allow your user to run Docker without sudo**\n\n```bash\nsudo usermod -aG docker $USER\n```\n\n**Log out and log back in** (or reboot) for this to take effect. After that, you can run `docker` commands without `sudo`.\n\n**Step 5: Verify the Installation**\n\n```bash\ndocker --version\ndocker run hello-world\n```\n\nYou should see `Docker version 27.x.x` and then `Hello from Docker!`.\n\n::: {.callout-note}\nOn a native Linux system, Docker Engine starts automatically via `systemd`. You do **not** need to start it manually (unlike in WSL 2). If it is not running, use:\n\n```bash\nsudo systemctl start docker\nsudo systemctl enable docker\n```\n:::\n\n::: {.callout-note}\n**From here, everything else in this guide works the same.** All `docker buildx build`, `docker compose`, and `docker run` commands work identically regardless of your operating system.\n:::\n\n---\n\n# Part 3: Understanding the Dockerfile\n\nBefore building our container, let us look at what goes inside the Dockerfile. You do not have to write this yourself --- we provide a ready-made Dockerfile. But understanding it helps you know what is happening.\n\nA Dockerfile is just a text file called `Dockerfile` (no extension) that lists instructions. Each instruction adds a \"layer\" to the image. Here is a simplified overview of what our Dockerfile does:\n\n```\n1. Start from a base Linux image (Ubuntu 24.04)\n2. Install system tools (curl, wget, git, build tools, LaTeX)\n3. Install R and R packages\n4. Install Python and Python packages\n5. Install Node.js (needed for Codex and Gemini CLI)\n6. Install Claude Code\n7. Install OpenAI Codex\n8. Install Google Gemini CLI\n9. Set up working directories\n```\n\n## Installing R Inside the Container\n\nOur Dockerfile adds the official CRAN repository for Ubuntu to get the latest stable R version, then installs R and common packages:\n\n```dockerfile\n# Add the CRAN repository for the latest R version\nRUN wget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | \\\n        tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc && \\\n    add-apt-repository \\\n        \"deb https://cloud.r-project.org/bin/linux/ubuntu noble-cran40/\"\n\n# Install R and system libraries needed by R packages\nRUN apt-get update && apt-get install -y r-base r-base-dev\n\n# Install R packages\nRUN Rscript -e \"install.packages(c('tidyverse', 'fixest', 'modelsummary', \\\n    'haven', 'data.table', 'rmarkdown'), \\\n    repos='https://cloud.r-project.org')\"\n```\n\n::: {.callout-tip}\nInstalling many R packages takes time. Our Dockerfile pre-installs \\~80 econometrics packages so you do not have to wait during the workshop.\n:::\n\n## Installing Python Inside the Container\n\n```dockerfile\n# Example: Installing Python with a virtual environment\nRUN apt-get install -y python3 python3-pip python3-venv\nRUN python3 -m venv /opt/venv\nENV PATH=\"/opt/venv/bin:$PATH\"\n\n# Install Python packages\nRUN pip install numpy pandas matplotlib jupyter\n```\n\n## Installing Stata Inside the Container (Special Case)\n\nUnlike R and Python, **Stata is commercial software**. You cannot freely download and install it. There are three options:\n\n**Option A: Use your university's Stata license (recommended if available)**\n\nIf your university provides a Stata license, you can install it inside the container. You will need:\n\n1. The Stata installer file (e.g., `Stata18Linux64.tar.gz`) --- ask your IT department\n2. Your license information (serial number, code, authorization)\n\n```dockerfile\n# Copy the Stata installer into the container\nCOPY Stata18Linux64.tar.gz /tmp/\nRUN cd /tmp && tar -xzf Stata18Linux64.tar.gz && \\\n    cd /tmp/Stata18 && ./install\n\n# You will need to initialize the license separately after the container starts:\n# Inside the container, run: stata -q -e \"exit\"\n# and enter your license details when prompted\n```\n\n::: {.callout-important}\nStata for Linux is different from Stata for Windows/Mac. Even if you have Stata on your laptop, you need a **Linux version** for the Docker container. Some university licenses include all platforms.\n:::\n\n**Option B: Mount Stata from your host system**\n\nIf you have Stata installed on your Mac/Windows machine, you can \"share\" it into the container using a Docker volume. This is more complex and depends on your specific Stata installation path.\n\n**Option C: Skip Stata and use R equivalents**\n\nFor many econometric analyses, R packages like `fixest`, `plm`, `ivreg`, and `rdrobust` can replicate Stata functionality. The workshop's CLAUDE.md includes a complete Stata-to-R mapping table for this purpose. This is the easiest option if you do not have a Linux Stata license.\n\n## Installing Node.js (Required for Codex and Gemini CLI)\n\nOpenAI Codex and Google Gemini CLI require Node.js. Claude Code uses a native binary installer and does not depend on Node.js.\n\n```dockerfile\n# Install Node.js 24 LTS\nRUN curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | \\\n        gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg && \\\n    echo \"deb [signed-by=/etc/apt/keyrings/nodesource.gpg] \\\n        https://deb.nodesource.com/node_24.x nodistro main\" | \\\n        tee /etc/apt/sources.list.d/nodesource.list > /dev/null && \\\n    apt-get update && apt-get install -y nodejs\n```\n\n---\n\n# Part 4: Building the Docker Image\n\nNow we will actually build the image. This is where Docker reads the Dockerfile and creates the frozen environment.\n\n**Step 1: Download the workshop files**\n\nOpen your terminal (Ubuntu on Windows, Terminal on Mac/Linux) and download or clone the workshop repository:\n\n```bash\n# Navigate to your home directory\ncd ~\n\n# Clone the workshop repository\ngit clone https://github.com/AlexRieber/Workshops.git\n\n# Enter the Docker workshop directory\ncd Workshops/Docker\n```\n\n::: {.callout-tip}\nIf you received the files as a ZIP, unzip them and navigate to the folder using `cd`.\n:::\n\n**Step 2: Build the image**\n\n```bash\ndocker buildx build -t coding-agent .\n```\n\nBreaking this command down:\n\n| Part | Meaning |\n|------|---------|\n| `docker buildx build` | Tell Docker to build an image |\n| `-t coding-agent` | Name the image `coding-agent` (you can choose any name) |\n| `.` | Look for the Dockerfile in the current directory |\n\n::: {.callout-note}\n## Build time: 20--30 minutes\nThe first build takes 20--30 minutes. Docker has to download the base image, install all system packages, compile R packages, etc.\n\n**Good news:** Docker *caches* every step. If you change only the CLAUDE.md file (for example) and rebuild, it takes seconds because Docker reuses the cached layers for everything else.\n:::\n\n**What to expect during the build:**\n\n- You will see lots of text scrolling by --- that is normal\n- Lines starting with `#6 [3/12] RUN apt-get...` show progress through the build steps\n- Warnings about deprecated package versions are usually harmless\n- If the build fails, read the last few lines of error output --- they usually tell you what went wrong\n\n**Step 3: Verify the image was created**\n\n```bash\ndocker images\n```\n\nYou should see `coding-agent` in the list with a size of several gigabytes.\n\n---\n\n# Part 5: Running the Container\n\n## Starting the Container (Simple Version)\n\nFor a quick start, run:\n\n```bash\ndocker run -it \\\n  --name my-agent \\\n  -v \"$(pwd)/workspace\":/home/agent/project \\\n  -v \"$(pwd)/output\":/home/agent/output \\\n  coding-agent \\\n  bash\n```\n\nThis command:\n\n| Part | What It Does |\n|------|--------------|\n| `docker run -it` | Start a new container in interactive mode (you can type commands) |\n| `--name my-agent` | Give the container a name so you can refer to it later |\n| `-v \"$(pwd)/workspace\":/home/agent/project` | Share the `workspace/` folder between your computer and the container |\n| `-v \"$(pwd)/output\":/home/agent/output` | Share the `output/` folder for results |\n| `coding-agent` | Use the image we built |\n| `bash` | Open a bash shell inside the container |\n\nYou are now *inside* the container. Your prompt changes to something like `root@a1b2c3d4:/home/agent#`.\n\n::: {.callout-tip}\nThe `workspace/` and `output/` folders are shared between the container and your computer. Anything the AI agent saves there, you can see on your host system. Everything else inside the container is isolated.\n:::\n\n## Starting the Container (Recommended: with Resource Limits)\n\nFor a more controlled setup, use `docker compose`. Create a file called `docker-compose.yml` in your project directory:\n\n```yaml\nservices:\n  agent:\n    image: coding-agent\n    container_name: my-agent\n    stdin_open: true\n    tty: true\n    mem_limit: 16g\n    memswap_limit: 16g\n    cpus: 4\n    pids_limit: 512\n    volumes:\n      - ./workspace:/home/agent/project\n      - ./output:/home/agent/output\n      - ./CLAUDE.md:/home/agent/CLAUDE.md:ro\n      - agent-auth:/root/.claude\n    working_dir: /home/agent\n\nvolumes:\n  agent-auth:\n```\n\nThen run:\n\n```bash\n# Create the shared folders if they do not exist\nmkdir -p workspace output\n\n# Start the container in the background\ndocker compose up -d\n\n# Enter the running container\ndocker exec -it my-agent bash\n```\n\n## What Are Resource Limits and Why?\n\n| Setting | Value | Purpose |\n|---------|-------|---------|\n| `mem_limit: 16g` | Max 16 GB RAM | Prevents the agent from using all your computer's memory |\n| `memswap_limit: 16g` | No swap allowed | Prevents slow-down from excessive swapping |\n| `cpus: 4` | Max 4 CPU cores | Leaves CPU capacity for your other applications |\n| `pids_limit: 512` | Max 512 processes | Prevents runaway process creation (fork bombs) |\n\n## Exiting and Re-entering the Container\n\n```bash\n# To leave the container (it keeps running):\nexit\n\n# To re-enter a running container:\ndocker exec -it my-agent bash\n\n# To stop the container:\ndocker compose down\n\n# To start it again later:\ndocker compose up -d\n```\n\n---\n\n# Part 6: Setting Up Claude Code\n\nClaude Code is Anthropic's terminal-based AI coding agent. It reads files, writes code, runs commands, and iterates on errors --- all from the command line. There are two ways to authenticate.\n\n## Option A: Anthropic API Key (Pay-per-use)\n\nThis option charges you per token (per amount of text processed). You control your spending through the API dashboard.\n\n**Step 1: Get an API key**\n\n1. Go to: **[https://platform.claude.com/](https://platform.claude.com/)**\n2. Create an account (or sign in)\n3. Go to **\"API Keys\"** in the left sidebar\n4. Click **\"Create Key\"**, give it a name (e.g., \"workshop\"), and copy the key\n5. **Important:** The key starts with `sk-ant-...`. Save it somewhere safe --- you will not be able to see it again.\n6. Add credit to your account under **\"Billing\"** (even $5--10 is enough for a workshop session)\n\n**Step 2: Install Claude Code inside the container**\n\nOur Dockerfile already includes Claude Code. If you need to install it manually:\n\n```bash\n# Inside the container:\ncurl -fsSL https://claude.ai/install.sh | bash\n```\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 1--2 minutes\n:::\n\n**Step 3: Authenticate with the API key**\n\n```bash\n# Inside the container, set the API key:\nexport ANTHROPIC_API_KEY=\"sk-ant-your-key-here\"\n\n# Start Claude Code:\nclaude\n```\n\nClaude Code will detect the API key and start immediately.\n\n::: {.callout-tip}\nTo avoid re-entering the key every time, add it to the container's shell profile:\n\n```bash\necho 'export ANTHROPIC_API_KEY=\"sk-ant-your-key-here\"' >> ~/.bashrc\n```\n:::\n\n## Option B: Claude Max Subscription (Fixed Monthly Cost)\n\nIf you have a Claude Pro ($20/month) or Max ($100 or $200/month) subscription, you can use Claude Code without API charges. Usage counts against your subscription's rate limits.\n\n**Step 1: Get a subscription**\n\n1. Go to: **[https://claude.ai/](https://claude.ai/)**\n2. Sign up or sign in\n3. Upgrade to Pro or Max under account settings\n\n**Step 2: Authenticate inside the container**\n\n```bash\n# Inside the container:\nclaude\n```\n\nClaude Code will display a message like:\n\n```\nTo authenticate, visit:\nhttps://claude.ai/login?code=ABCD-1234-EFGH\n```\n\n1. **Copy** the URL from the terminal\n2. **Open** the URL in a web browser on your host machine (your laptop)\n3. Sign in with your Claude account\n4. Click **\"Authorize\"**\n5. Back in the terminal, you should see: `Authenticated successfully!`\n\n::: {.callout-note}\n**The login is saved.** If you used `docker-compose.yml` with the `agent-auth` volume (as shown above), your login persists even if you stop, remove, and recreate the container. You only need to log in once.\n:::\n\n## Verifying Claude Code Works\n\nAfter authentication (either method), test it:\n\n```bash\nclaude --version\n```\n\nThen start an interactive session:\n\n```bash\nclaude\n```\n\nYou should see the Claude Code interface. Type a simple test message like `What is 2+2?` and press Enter. If you get a response, everything is working.\n\n## Running Claude Code with Specific Models\n\n```bash\n# Use the default model (Sonnet):\nclaude\n\n# Use the most capable model (Opus --- requires Max $200 or API):\nclaude --model opus\n\n# See real-time thinking (recommended for learning):\nclaude --verbose\n```\n\n---\n\n# Part 7: Setting Up OpenAI Codex\n\nOpenAI Codex is OpenAI's terminal-based AI coding agent, similar in concept to Claude Code. It is open source (Apache 2.0 license) and available on GitHub at [https://github.com/openai/codex](https://github.com/openai/codex).\n\n## Authentication Options for Codex\n\nLike Claude Code, Codex supports two authentication methods:\n\n| Method | What You Need | Cost Model |\n|--------|---------------|------------|\n| **OpenAI API Key** | API key from platform.openai.com | Pay-per-token |\n| **ChatGPT Subscription** | ChatGPT Plus, Pro, or Enterprise plan | Included in subscription |\n\n::: {.callout-important}\nThe ChatGPT subscription login uses a browser-based OAuth flow that opens a local web server on port 1455. This is difficult to use from inside a Docker container. For Docker setups, **we recommend using an API key**.\n:::\n\n## Step 1: Get an OpenAI API Key\n\n1. Go to: **[https://platform.openai.com/](https://platform.openai.com/)**\n2. Create an account (or sign in)\n3. Go to **\"API Keys\"** in the sidebar\n4. Click **\"Create new secret key\"**, give it a name, and copy the key\n5. The key starts with `sk-...`. Save it somewhere safe.\n6. Add credit under **\"Billing\"** (again, $5--10 is plenty for experimenting)\n\n## Step 2: Install Codex Inside the Container\n\nOur Dockerfile already includes Codex. If you need to install it manually:\n\n```bash\n# Inside the container:\nnpm install -g @openai/codex\n```\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 1--2 minutes\n:::\n\n## Step 3: Authenticate and Run\n\n```bash\n# Set the API key:\nexport OPENAI_API_KEY=\"sk-your-key-here\"\n\n# Start Codex interactively:\ncodex\n```\n\nFor **non-interactive** use (e.g., in scripts), Codex provides the `exec` subcommand:\n\n```bash\ncodex exec \"analyze the data in data.csv and create a summary\"\n```\n\n## Step 4: Useful Codex Flags\n\n| Flag | What It Does |\n|------|--------------|\n| `--full-auto` | Agent applies changes without asking for approval |\n| `--sandbox danger-full-access` | Disable sandboxing (appropriate when already in Docker) |\n| `--model <name>` | Choose which OpenAI model to use (e.g., `o3-mini`) |\n\n::: {.callout-note}\n**Note on sandboxing:** Codex has its own built-in sandbox (using Linux Landlock on Linux). Since we are already running inside a Docker container (which is itself a sandbox), you can safely use `--sandbox danger-full-access` to avoid sandboxing conflicts. The Docker container provides the isolation.\n:::\n\n---\n\n# Part 8: Setting Up Google Gemini CLI\n\nGoogle Gemini CLI is Google's open-source terminal-based AI coding agent (Apache 2.0 license), available on GitHub at [https://github.com/google-gemini/gemini-cli](https://github.com/google-gemini/gemini-cli). It provides access to Gemini models with a 1M token context window.\n\n## Authentication Options for Gemini CLI\n\n| Method | What You Need | Cost Model |\n|--------|---------------|------------|\n| **Google AI Studio API Key** | API key from aistudio.google.com | Free tier (limits vary by model) |\n| **Google Account Login** | Personal Google account | Free (same limits as above) |\n| **Vertex AI** | Google Cloud project with billing | Pay-per-token |\n\n## Option A: Google AI Studio API Key (Recommended)\n\n**Step 1: Get an API key**\n\n1. Go to: **[https://aistudio.google.com/](https://aistudio.google.com/)**\n2. Sign in with your Google account\n3. Click **\"Get API key\"** → **\"Create API key\"**\n4. Copy the key and save it somewhere safe\n\n::: {.callout-tip}\nThe free tier is generous for the default model (Gemini Flash). Limits vary by model --- more capable models like Gemini Pro have lower quotas. Either way, the free tier is more than enough for a workshop session without spending any money.\n:::\n\n**Step 2: Install Gemini CLI inside the container**\n\nOur Dockerfile already includes Gemini CLI. If you need to install it manually:\n\n```bash\n# Inside the container:\nnpm install -g @google/gemini-cli\n```\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 1--2 minutes\n:::\n\n**Step 3: Authenticate with the API key**\n\n```bash\n# Inside the container, set the API key:\nexport GEMINI_API_KEY=\"your-key-here\"\n\n# Start Gemini CLI:\ngemini\n```\n\n## Option B: Google Account Login (No API Key Needed)\n\nIf you prefer not to create an API key, Gemini CLI can authenticate directly with your Google account:\n\n```bash\n# Inside the container:\ngemini\n```\n\nOn first run, Gemini CLI will display a URL. Open it in your browser, sign in with your Google account, and authorize the application. The same free tier limits apply.\n\n::: {.callout-important}\nThe browser login flow requires network access from the container. If you are on a restricted network, use the API key method instead.\n:::\n\n## Verifying Gemini CLI Works\n\n```bash\ngemini --version\n```\n\nThen start an interactive session:\n\n```bash\ngemini\n```\n\nType a test message. If you get a response, everything is working.\n\n---\n\n# Part 9: The Complete Dockerfile {#part-9}\n\nThe complete Dockerfile is available in the workshop repository:\n\n**[`Dockerfile` on GitHub](https://github.com/AlexRieber/Workshops/blob/main/Docker/Dockerfile)**\n\nIf you cloned the repository (see Part 4), you already have this file. Otherwise, download it directly and place it in your project directory as `Dockerfile` (no file extension).\n\nHere is what each section of the Dockerfile does:\n\n| Layer | What It Does |\n|-------|--------------|\n| **Base image** (`FROM ubuntu:24.04`) | Starts from a clean Ubuntu 24.04 LTS Linux system |\n| **System tools** | Installs `curl`, `wget`, `git`, `nano`, `jq`, `tree`, build tools, and LaTeX (for rendering R Markdown / Quarto documents) |\n| **R + R packages** | Adds the CRAN repository for the latest stable R, then installs R plus \\~25 core econometrics and data science packages (tidyverse, fixest, modelsummary, haven, etc.). This is the slowest step (\\~10--15 min). |\n| **Python + packages** | Installs Python 3 in a virtual environment with `numpy`, `pandas`, `matplotlib`, and `jupyter` |\n| **AI provider SDKs** | Installs the `openai`, `anthropic`, and `google-genai` Python SDKs for building custom agents |\n| **Aider** | Open-source AI coding agent with built-in OpenRouter support (use any model) |\n| **Agent utilities** | `rich` (terminal formatting), `prompt_toolkit` (interactive input), `pydantic` (structured data) |\n| **Node.js 24 LTS** | Required runtime for OpenAI Codex and Google Gemini CLI |\n| **Claude Code** | Anthropic's terminal-based coding agent (native binary, does not require Node.js) |\n| **OpenAI Codex** | OpenAI's terminal-based coding agent |\n| **Google Gemini CLI** | Google's terminal-based coding agent |\n| **Working directories** | Creates the folder structure (`project/`, `output/`, `data/`, `code/`) |\n| **CMD** | Sets `bash` as the default command when the container starts |\n\n::: {.callout-tip}\n## Customizing the Dockerfile for your needs\n\nThe provided Dockerfile is a starting point. You will likely want to adapt it to your own research workflow --- for example, adding specific R or Python packages, additional system libraries, or different tools.\n\n**Ask your preferred LLM to help you.** Copy the Dockerfile into a chat with ChatGPT, Claude, Gemini, or whichever model you prefer and describe what you need:\n\n- *\"I need to add the `sf` and `terra` R packages for geospatial analysis. What system libraries do I need and how should I modify this Dockerfile?\"*\n- *\"I want to add Julia to this container. What lines should I add?\"*\n- *\"I work with LaTeX documents using Biblatex. What do I need to add?\"*\n\nLLMs are excellent at writing and debugging Dockerfiles. They can suggest the right `apt-get` packages, handle dependency chains, and help you keep the image size manageable. This is a great way to learn Docker syntax while getting a setup tailored to your needs.\n:::\n\n::: {.callout-note}\n## Build time expectations\n\n| Step | Approximate Time |\n|------|-----------------|\n| Download base image | 1--2 min |\n| System tools + LaTeX | 3--5 min |\n| R + R packages | 10--15 min |\n| Python + packages | 2--3 min |\n| Node.js + Claude Code + Codex + Gemini CLI | 3--5 min |\n| **Total (first build)** | **\\~20--30 min** |\n| **Rebuild after changing only CLAUDE.md** | **< 10 seconds** |\n:::\n\n---\n\n# Part 10: Putting It All Together (Full Walkthrough)\n\nHere is the complete process from zero to a running agent. Follow these steps in order.\n\n## 1. Install Docker (\\~10 min)\n\n- **Windows:** Follow Part 2, Option A (install WSL 2, then Docker Desktop) or Option B (Docker Engine in WSL 2)\n- **Mac:** Follow Part 2, Option A (download and install Docker Desktop)\n- **Linux:** Follow Part 2, Option C (install Docker Engine directly)\n- Verify with `docker run hello-world`\n\n## 2. Create Your Project Folder (\\~2 min)\n\nOpen your terminal (Ubuntu on Windows, Terminal on Mac/Linux):\n\n```bash\nmkdir -p ~/coding-agent-workshop\ncd ~/coding-agent-workshop\nmkdir -p workspace output\n```\n\n## 3. Get the Dockerfile (\\~2 min)\n\nIf you cloned the repository in step 1 of Part 4, the `Dockerfile` is already included. Otherwise, download it from the [workshop repository on GitHub](https://github.com/AlexRieber/Workshops/blob/main/Docker/Dockerfile) and save it as `Dockerfile` (no extension) in `~/coding-agent-workshop/`. On the command line, you can open the folder:\n\n::: {.os-compare}\n\n::: {.windows}\nOpen the folder in Explorer:\n\n```bash\nexplorer.exe $(wslpath -w ~/coding-agent-workshop)\n```\n:::\n\n::: {.mac}\nOpen the folder in Finder:\n\n```bash\nopen ~/coding-agent-workshop\n```\n:::\n\n:::\n\nThen place the `Dockerfile` (no extension!) in this folder.\n\n## 4. Create the docker-compose.yml (\\~1 min)\n\nCreate `docker-compose.yml` in the same folder with the content from Part 5.\n\n## 5. Build the Image (\\~20--30 min)\n\n```bash\ncd ~/coding-agent-workshop\ndocker buildx build -t coding-agent .\n```\n\nGo get a coffee. This will take a while the first time.\n\n## 6. Start the Container (\\~10 sec)\n\n```bash\ndocker compose up -d\ndocker exec -it my-agent bash\n```\n\nYou are now inside the container.\n\n## 7. Verify Everything Is Installed (\\~1 min)\n\nInside the container, run:\n\n```bash\n# Check R\nR --version | head -1\n\n# Check Python\npython3 --version\n\n# Check Node.js\nnode --version\n\n# Check Claude Code\nclaude --version\n\n# Check Codex\ncodex --version\n\n# Check Gemini CLI\ngemini --version\n\n# Check Aider\naider --version\n```\n\nAll commands should print a version number.\n\n## 8. Authenticate Your AI Agent (\\~2 min)\n\n**For Claude Code:**\n\n```bash\n# Option A: API key\nexport ANTHROPIC_API_KEY=\"sk-ant-your-key-here\"\nclaude\n\n# Option B: Max subscription\nclaude\n# Follow the browser login flow (see Part 6)\n```\n\n**For OpenAI Codex:**\n\n```bash\nexport OPENAI_API_KEY=\"sk-your-key-here\"\ncodex\n```\n\n**For Google Gemini CLI:**\n\n```bash\nexport GEMINI_API_KEY=\"your-key-here\"\ngemini\n```\n\n## 9. Start Working\n\nYou are ready! Give the agent a task:\n\n```bash\n# Claude Code (interactive):\nclaude\n\n# Or with verbose output to see its reasoning:\nclaude --verbose\n```\n\n---\n\n# Part 11: Everyday Commands (Cheat Sheet)\n\n## Starting and Stopping\n\n```bash\n# Start the container (from your project folder)\ndocker compose up -d\n\n# Enter the container\ndocker exec -it my-agent bash\n\n# Leave the container (it keeps running)\nexit\n\n# Stop the container\ndocker compose down\n```\n\n## Inside the Container\n\n```bash\n# Start Claude Code\nclaude\n\n# Start Claude Code with Opus model and verbose output\nclaude --model opus --verbose\n\n# Start OpenAI Codex\ncodex\n\n# Start Google Gemini CLI\ngemini\n\n# Start Aider with an OpenRouter model\nOPENROUTER_API_KEY=\"sk-or-...\" aider --model openrouter/moonshotai/kimi-k2\n\n# Run an R script\nRscript my_analysis.R\n\n# Start an interactive R session\nR\n\n# Start Python\npython3\n```\n\n## Managing Docker (on your host system)\n\n```bash\n# See running containers\ndocker ps\n\n# See all images\ndocker images\n\n# See resource usage of a running container\ndocker stats my-agent\n\n# Rebuild the image after changing the Dockerfile\ndocker buildx build -t coding-agent .\n\n# Remove the container (data in workspace/ and output/ is preserved)\ndocker rm -f my-agent\n\n# Remove the image (frees disk space)\ndocker rmi coding-agent\n\n# Nuclear option: remove everything Docker-related (containers, images, volumes)\n# WARNING: This deletes ALL Docker data, including saved authentication!\ndocker system prune -a --volumes\n```\n\n---\n\n# Part 12: Troubleshooting\n\n## Installation Problems\n\n| Problem | Solution |\n|---------|----------|\n| **Windows: \"WSL 2 installation is incomplete\"** | Open PowerShell as Admin, run `wsl --update`, restart |\n| **Windows: \"Hardware assisted virtualization is not enabled\"** | Enable VT-x/AMD-V in your BIOS settings (search for your laptop model + \"enable virtualization\") |\n| **Windows: Docker Desktop does not start** | Run `wsl --status` in PowerShell. If WSL is not running, try `wsl --shutdown` then restart Docker Desktop |\n| **Mac: \"Docker Desktop requires macOS 14 or later\"** | Update your macOS, or try an older version of Docker Desktop |\n| **`docker: command not found`** | Docker Desktop is not running, or the PATH is not set. Restart Docker Desktop. On Windows, make sure you are using the Ubuntu terminal. |\n\n## Build Problems\n\n| Problem | Solution |\n|---------|----------|\n| **Build fails at R package installation** | Some R packages need system libraries. Check the error message for missing `-dev` packages and add them to the `apt-get install` line in the Dockerfile |\n| **Build runs out of disk space** | Increase Docker Desktop's disk image size (Settings → Resources) and run `docker system prune` to free space |\n| **Build is very slow** | First builds are always slow. Subsequent rebuilds use cached layers and are much faster |\n| **\"network error\" during build** | Check your internet connection. Some corporate/university networks block Docker Hub. Try a different network or VPN. |\n\n## Runtime Problems\n\n| Problem | Solution |\n|---------|----------|\n| **Container immediately exits** | Use `docker run -it ... bash` (the `-it` flags keep it interactive) |\n| **`claude`, `codex`, `gemini`, or `aider` command not found** | Rebuild the image: `docker buildx build -t coding-agent .` |\n| **Claude Code: \"Authentication required\"** | Follow the login steps in Part 6. For API key: check that `ANTHROPIC_API_KEY` is set (`echo $ANTHROPIC_API_KEY`) |\n| **Codex: \"API key not found\"** | Check that `OPENAI_API_KEY` is set (`echo $OPENAI_API_KEY`) |\n| **Gemini CLI: authentication error** | Follow login steps in Part 8. For API key: check that `GEMINI_API_KEY` is set (`echo $GEMINI_API_KEY`) |\n| **\"No space left on device\" in container** | The container's disk is full. Remove unnecessary files, or increase Docker's disk image size |\n| **Everything is very slow** | Check Docker Desktop resource settings (Part 2). Give Docker more RAM and CPUs. On Windows: make sure files are in the WSL filesystem (`~/...`), not in `/mnt/c/...` |\n| **Lost authentication after container restart** | Make sure you are using the `agent-auth` volume in `docker-compose.yml` (see Part 5). Without it, auth is lost when the container is removed. |\n\n---\n\n# Part 13: Security and Isolation\n\nRunning an AI coding agent means giving software the ability to read files, write files, run commands, and access the internet. This section explains how Docker keeps you safe, and how to add extra layers of protection.\n\n## What the Container CAN Do\n\n- Read and write files inside the container\n- Access files in the mounted `workspace/` and `output/` folders\n- Make network requests (download data, call APIs)\n- Install software inside the container\n\n## What the Container CANNOT Do\n\n- Access files on your host system outside of the mounted folders\n- Modify your operating system or installed software\n- Access other running applications on your computer\n- Persist changes (except in mounted volumes) after being deleted\n\n## Best Practices\n\n1. **Never put sensitive files** (passwords, private keys, personal data) in the `workspace/` or `output/` folders\n2. **Review output** before sharing it --- AI agents can sometimes include unexpected content\n3. **Use resource limits** (as shown in the `docker-compose.yml`) to prevent runaway resource usage\n4. **Store API keys carefully** --- do not commit them to Git repositories. Use environment variables.\n5. **Regularly stop containers** you are not using --- they consume system resources even when idle\n\n---\n\n# Part 14: Advanced Safety --- Isolating Docker on Its Own Partition\n\n## Why a Separate Partition?\n\nBy default, Docker stores all its data (images, containers, volumes) on your main system drive. An autonomous AI agent could, in theory:\n\n- Download very large datasets, filling up your disk\n- Create many intermediate files during analysis\n- Pull additional Docker images\n\nIf your main drive runs out of space, your **entire system** can become unstable --- not just the container. The solution is to give Docker its own, separate storage area with a hard size limit. If that area fills up, Docker stops working but your operating system and personal files stay safe.\n\nThink of it like giving someone a dedicated filing cabinet rather than access to your entire office. When the cabinet is full, they cannot fill up anything else.\n\n## Option A: Move Docker Desktop's Storage (Recommended --- Easiest)\n\nThis is the simplest approach and works well for most students.\n\n::: {.windows}\n\n### Windows\n\nDocker Desktop on Windows stores its data inside WSL 2. You can move this to a different drive:\n\n**Step 1:** Stop Docker Desktop (right-click the whale icon in the system tray, select \"Quit Docker Desktop\")\n\n**Step 2:** Open PowerShell as Administrator:\n\n```powershell\n# Stop WSL\nwsl --shutdown\n\n# Export the Docker data distribution to your target drive\nwsl --export docker-desktop-data D:\\DockerData\\docker-desktop-data.tar\n\n# Unregister the original (this removes it from your C: drive)\nwsl --unregister docker-desktop-data\n\n# Import it at the new location with a size you control\nwsl --import docker-desktop-data D:\\DockerData D:\\DockerData\\docker-desktop-data.tar\n\n# Clean up the export file\ndel D:\\DockerData\\docker-desktop-data.tar\n```\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** 5--15 minutes depending on how much Docker data you already have.\n\nReplace `D:\\DockerData` with any folder on a drive with enough space. If you have an external SSD or a second internal drive, use that.\n:::\n\n::: {.callout-important}\nRecent versions of Docker Desktop (4.30+) may no longer create a separate `docker-desktop-data` WSL distribution. If the `wsl --export docker-desktop-data` command fails, use Docker Desktop's built-in setting instead: **Settings → Resources → Disk image location** and move the storage from there.\n:::\n\n**Step 3:** Restart Docker Desktop. All Docker operations now use the new location.\n\n:::\n\n::: {.mac}\n\n### Mac\n\nOn Mac, Docker Desktop stores its data in a single disk image file. You can control its location and size:\n\n1. Open **Docker Desktop → Settings → Resources → Disk image location**\n2. Click **\"Browse\"** and select a folder on a different volume or external drive\n3. Set the **\"Disk image size\"** to your desired limit (e.g., 60 GB)\n4. Click **\"Apply & restart\"**\n\nDocker will move its data to the new location. This may take a few minutes.\n\n:::\n\n## Option B: Create a Dedicated Disk Image (Advanced --- Maximum Isolation)\n\nThis approach creates a fixed-size virtual disk that Docker uses. When it fills up, Docker hits a wall but your system stays safe. This is ideal for running AI agents that you want to constrain strictly.\n\n::: {.windows}\n\n### Windows (WSL 2)\n\nOn Windows, Docker runs inside WSL 2, which already uses a virtual disk (`.vhdx` file). You can control its maximum size:\n\n**Step 1:** Stop Docker Desktop and WSL:\n\n```powershell\nwsl --shutdown\n```\n\n**Step 2:** Create a `.wslconfig` file in your Windows home directory (`C:\\Users\\YourName\\.wslconfig`) with:\n\n```ini\n[wsl2]\n# Limit WSL 2 resource usage\nmemory=8GB\nprocessors=4\nswap=0\n```\n\n::: {.callout-note}\nThis `.wslconfig` file limits WSL 2's memory and CPU usage but does **not** directly cap the virtual disk size. The virtual disk (`ext4.vhdx`) grows dynamically up to 256 GB by default. To shrink an existing one, you need to use `diskpart` in PowerShell --- this is more complex and not necessary for a fresh setup. For hard disk limits on Windows, use Option A (move Docker storage to a drive with limited free space) instead.\n:::\n\n**Step 3:** Restart WSL and Docker Desktop.\n\n:::\n\n::: {.mac}\n\n### Mac\n\nOn Mac, you can create a dedicated APFS or HFS+ disk image:\n\n**Step 1:** Open **Disk Utility** (Spotlight: Cmd+Space, type \"Disk Utility\")\n\n**Step 2:** Go to **File → New Image → Blank Image** and configure:\n\n| Setting | Value |\n|---------|-------|\n| **Name** | DockerWorkspace |\n| **Size** | 60 GB (or your preferred limit) |\n| **Format** | APFS |\n| **Partitions** | Single partition - GUID |\n| **Image Format** | sparse disk image (grows as needed, up to the size limit) |\n\n**Step 3:** Click **\"Save\"**. The disk image (`.sparseimage`) will be created.\n\n::: {.callout-note appearance=\"minimal\"}\n**Expected time:** < 1 minute\n:::\n\n**Step 4:** Double-click the `.sparseimage` file to mount it. It appears as a drive in Finder (e.g., `/Volumes/DockerWorkspace`).\n\n**Step 5:** Point Docker Desktop to this location:\n\n1. Open **Docker Desktop → Settings → Resources → Disk image location**\n2. Set it to `/Volumes/DockerWorkspace`\n3. Click **\"Apply & restart\"**\n\n**Step 6: After every reboot**, double-click the `.sparseimage` file to mount it before starting Docker Desktop. Or automate it by adding it to your Login Items (System Settings → General → Login Items → add the `.sparseimage` file).\n\n:::\n\n## Option C: Create a Size-Limited Workspace Folder (Simplest Extra Protection)\n\nIf options A and B feel too complex, you can simply limit the workspace folder that the container uses. This does not protect Docker's internal storage, but it does protect against the agent filling your drive with data files.\n\n::: {.os-compare}\n\n::: {.windows}\n```bash\n# Create a 30 GB disk image file\ndd if=/dev/zero of=~/agent_workspace.img \\\n   bs=1M count=30720 status=progress\n\n# Format it as a filesystem\nmkfs.ext4 ~/agent_workspace.img\n\n# Create the mount point and mount it\nmkdir -p ~/coding-agent-workshop/workspace\nsudo mount -o loop ~/agent_workspace.img \\\n     ~/coding-agent-workshop/workspace\nsudo chmod 777 ~/coding-agent-workshop/workspace\n```\n\nAfter every reboot, re-mount with:\n\n```bash\nsudo mount -o loop ~/agent_workspace.img \\\n     ~/coding-agent-workshop/workspace\n```\n:::\n\n::: {.mac}\n```bash\n# Create a 30 GB sparse disk image\nhdiutil create -size 30g -fs APFS \\\n  -volname AgentWorkspace \\\n  -type SPARSE ~/agent_workspace.sparseimage\n\n# Mount it\nhdiutil attach ~/agent_workspace.sparseimage\n\n# Now use /Volumes/AgentWorkspace as your\n# workspace in docker-compose.yml\n```\n:::\n\n:::\n\nThen update your `docker-compose.yml` to use this mounted volume:\n\n```yaml\nvolumes:\n  - /Volumes/AgentWorkspace:/home/agent/project   # Mac\n  # or for Windows/WSL:\n  # - ~/coding-agent-workshop/workspace:/home/agent/project\n```\n\n## Understanding Volume Mounts: How Host Folders Connect to the Container\n\nVolume mounts are the bridge between your computer and the container. They control what the agent can see and where results appear.\n\n```\nYour Computer (Host)              Docker Container\n====================              ================\n\n~/coding-agent-workshop/          /home/agent/\n├── workspace/  ←──── volume ────→  project/      (agent reads & writes here)\n├── output/     ←──── volume ────→  output/       (results appear here)\n├── CLAUDE.md   ←──── volume ────→  CLAUDE.md     (read-only instructions)\n│\n├── Dockerfile  (not mounted, only used during build)\n└── my-files/   (NOT visible to container --- stays private)\n```\n\n**Key rules:**\n\n- The agent can **only** access folders you explicitly mount with `-v` or `volumes:` in `docker-compose.yml`\n- Anything NOT mounted is invisible to the container\n- Mounts are bidirectional: changes inside the container appear on your host, and vice versa\n- Use `:ro` (read-only) to mount files the agent should read but not change (e.g., `CLAUDE.md:ro`)\n\n**Choosing your shared folder:** You decide where on your host the shared folder lives. Here is how to think about it:\n\n| What You Want | How to Set It Up |\n|---------------|------------------|\n| **Simple sharing** in your project folder | `-v ./workspace:/home/agent/project` (the default) |\n| **Shared folder on a different drive** | `-v /Volumes/ExternalSSD/agent-data:/home/agent/project` (Mac) or `-v /mnt/d/agent-data:/home/agent/project` (Windows/WSL) |\n| **Size-limited workspace** | Mount a disk image (see Option C above), then use that as the volume path |\n| **Read-only data sharing** | `-v ~/my-datasets:/home/agent/data:ro` --- agent can read your datasets but not modify them |\n| **Multiple shared folders** | Add multiple `-v` lines, each mapping a different host path to a different container path |\n\n## Summary: Picking Your Isolation Level\n\n| Level | Setup Effort | What It Protects | Recommended For |\n|-------|-------------|------------------|-----------------|\n| **Default Docker** (container only) | None | Agent cannot escape the container | Quick experiments, supervised sessions |\n| **Resource limits** (docker-compose.yml) | Low | Limits RAM, CPU, processes | All use cases (always recommended) |\n| **Size-limited workspace** (Option C) | Medium | Prevents agent from filling your disk with data | Longer autonomous sessions |\n| **Separate Docker storage** (Option A) | Medium | Keeps Docker data off your system drive | Regular Docker users |\n| **Dedicated disk image** (Option B) | High | Hard cap on ALL Docker storage | Maximum safety, unattended agents |\n\n::: {.callout-tip}\n## Our recommendation for the workshop\nUse the default Docker setup with resource limits (docker-compose.yml from Part 5). This provides excellent isolation with minimal setup. Add Option C (size-limited workspace) if you plan to let agents run for extended periods.\n:::\n\n---\n\n# Glossary\n\n| Term | Definition |\n|------|-----------|\n| **Container** | A running, isolated environment created from an image. Like a lightweight virtual machine. |\n| **Dockerfile** | A text file with instructions for building an image. |\n| **Image** | A frozen snapshot of an environment. Containers are created from images. |\n| **Volume** | A way to share data between your host system and a container, or to persist data across container restarts. |\n| **WSL 2** | Windows Subsystem for Linux --- lets you run Linux tools on Windows. Required by Docker Desktop on Windows. |\n| **API Key** | A secret string that authenticates you with an AI service. Like a password for the API. |\n| **Sandbox** | An isolated environment where software can run without affecting the rest of the system. |\n| **Terminal** | A text-based interface for running commands. \"Ubuntu\" app on Windows, \"Terminal\" app on Mac and Linux. |\n| **Shell** | The program that interprets your commands in the terminal (usually `bash` or `zsh`). |\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","filters":["os-boxes.lua"],"css":["howto-html.css"],"toc":true,"toc-depth":3,"number-sections":true,"embed-resources":true,"highlight-style":"github-dark","output-file":"docker-setup-howto.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","title":"Docker Setup Guide for AI Coding Agents","author":"Alexander Rieber ([\\@AlexRieber](https://github.com/AlexRieber)) · Ulm University","date":"2026-02-25","theme":"cosmo"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}